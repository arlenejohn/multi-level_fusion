{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9ff566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mat4py import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from scipy import signal\n",
    "import os\n",
    "from scipy.linalg import circulant\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116daa12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0695a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('D:\\PhD topics\\Datasets\\Afib_datasets\\store_noise_one_mean_final2_-20.pkl', 'rb')\n",
    "#file= open('store_no_noise.pkl','rb')\n",
    "obj = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1599af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train=obj['ecg_train']\n",
    "ecg_valid=obj['ecg_valid']\n",
    "ecg_test=obj['ecg_test']\n",
    "ppg_train=obj['ppg_train']\n",
    "ppg_valid=obj['ppg_valid']\n",
    "ppg_test=obj['ppg_test']\n",
    "y_train=obj['y_train']\n",
    "y_valid=obj['y_valid']\n",
    "y_test=obj['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab2e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_sqi_train=obj['ecg_sqi_train']\n",
    "ppg_sqi_train=obj['ppg_sqi_train']\n",
    "ecg_sqi_valid=obj['ecg_sqi_valid']\n",
    "ppg_sqi_valid=obj['ppg_sqi_valid']\n",
    "ecg_sqi_test=obj['ecg_sqi_test']\n",
    "ppg_sqi_test=obj['ppg_sqi_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351e0421",
   "metadata": {},
   "outputs": [],
   "source": [
    "del obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216ffaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.isnan(ecg_train).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056519fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06349457,  0.08844781, -0.0326824 , ...,  0.02655176,\n",
       "         0.09326861,  0.11718857],\n",
       "       [ 0.01169633,  0.01169633,  0.01169633, ...,  0.01180454,\n",
       "         0.01180454,  0.01169633],\n",
       "       [-0.1079712 ,  0.14550357, -0.02788106, ..., -0.12567619,\n",
       "         0.12003856,  0.11083796],\n",
       "       ...,\n",
       "       [-0.246522  ,  0.79480254,  1.42390128, ..., -0.0849805 ,\n",
       "        -0.69458182,  0.44167311],\n",
       "       [-0.25915785,  0.18577151, -0.18441675, ...,  0.29162016,\n",
       "         0.59671575,  0.34884971],\n",
       "       [ 0.05922131,  0.06896764,  0.07886163, ..., -0.05271372,\n",
       "        -0.05064632, -0.04976029]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d63e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_sqi_train_mean=np.mean(ecg_sqi_train, axis=0)\n",
    "ecg_sqi_train_std=np.std(ecg_sqi_train, axis=0)\n",
    "\n",
    "for i in range(ecg_sqi_train.shape[0]):\n",
    "    ecg_sqi_train[i,:]=(ecg_sqi_train[i,:]-ecg_sqi_train_mean)/ecg_sqi_train_std\n",
    "    \n",
    "for i in range(ecg_sqi_valid.shape[0]):\n",
    "    ecg_sqi_valid[i,:]=(ecg_sqi_valid[i,:]-ecg_sqi_train_mean)/ecg_sqi_train_std\n",
    "    \n",
    "for i in range(ecg_sqi_test.shape[0]):\n",
    "    ecg_sqi_test[i,:]=(ecg_sqi_test[i,:]-ecg_sqi_train_mean)/ecg_sqi_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b966ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_sqi_train_mean=np.mean(ppg_sqi_train, axis=0)\n",
    "ppg_sqi_train_std=np.std(ppg_sqi_train, axis=0)\n",
    "\n",
    "for i in range(ppg_sqi_train.shape[0]):\n",
    "    ppg_sqi_train[i,:]=(ppg_sqi_train[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n",
    "    \n",
    "for i in range(ppg_sqi_valid.shape[0]):\n",
    "    ppg_sqi_valid[i,:]=(ppg_sqi_valid[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n",
    "    \n",
    "for i in range(ppg_sqi_test.shape[0]):\n",
    "    ppg_sqi_test[i,:]=(ppg_sqi_test[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b5e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train=np.expand_dims(ecg_train, axis=1)\n",
    "ecg_valid=np.expand_dims(ecg_valid, axis=1)\n",
    "ppg_train=np.expand_dims(ppg_train, axis=1)\n",
    "ppg_valid=np.expand_dims(ppg_valid, axis=1)\n",
    "\n",
    "ecg_sqi_train=np.expand_dims(ecg_sqi_train, axis=1)\n",
    "ecg_sqi_valid=np.expand_dims(ecg_sqi_valid, axis=1)\n",
    "ppg_sqi_train=np.expand_dims(ppg_sqi_train, axis=1)\n",
    "ppg_sqi_valid=np.expand_dims(ppg_sqi_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d4d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_test=np.expand_dims(ecg_test, axis=1)\n",
    "ppg_test=np.expand_dims(ppg_test, axis=1)\n",
    "\n",
    "\n",
    "ecg_sqi_test=np.expand_dims(ecg_sqi_test, axis=1)\n",
    "ppg_sqi_test=np.expand_dims(ppg_sqi_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ff3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "308738bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_train_num = y_train_encoder.fit_transform(y_train)\n",
    "y_train_wide = to_categorical(y_train_num, num_classes)\n",
    "\n",
    "y_valid_num = y_train_encoder.fit_transform(y_valid)\n",
    "y_valid_wide = to_categorical(y_valid_num, num_classes)\n",
    "\n",
    "y_test_num = y_train_encoder.fit_transform(y_test)\n",
    "y_test_wide = to_categorical(y_test_num, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "134c8abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fusion_model_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #ecg alone\n",
    "        self.bn1_ecg=nn.BatchNorm1d(1)\n",
    "        self.conv1_ecg = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ecg = nn.LeakyReLU()\n",
    "        self.max1_ecg = nn.MaxPool1d(2)\n",
    "        self.drop1_ecg=nn.Dropout(0.25)\n",
    "        self.conv2_ecg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ecg = nn.MaxPool1d(2)\n",
    "        self.relu2_ecg = nn.LeakyReLU()\n",
    "        self.drop2_ecg=nn.Dropout(0.25)\n",
    "        self.conv3_ecg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ecg=nn.Dropout(0.25)\n",
    "        self.conv4_ecg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ecg = nn.MaxPool1d(2)\n",
    "        self.relu4_ecg = nn.LeakyReLU()\n",
    "        self.bn2_ecg=nn.BatchNorm1d(5)\n",
    "        self.flat_ecg=nn.Flatten()\n",
    "        self.drop4_ecg=nn.Dropout(0.25)\n",
    "        self.linear1_ecg=nn.Linear(660,2)\n",
    "        self.softm_ecg=nn.Softmax()\n",
    "        \n",
    "        #ppg alone\n",
    "        self.bn1_ppg=nn.BatchNorm1d(1)\n",
    "        self.conv1_ppg = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ppg = nn.LeakyReLU()\n",
    "        self.max1_ppg = nn.MaxPool1d(2)\n",
    "        self.drop1_ppg=nn.Dropout(0.25)\n",
    "        self.conv2_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ppg = nn.MaxPool1d(2)\n",
    "        self.relu2_ppg = nn.LeakyReLU()\n",
    "        self.drop2_ppg=nn.Dropout(0.25)\n",
    "        self.conv3_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ppg=nn.Dropout(0.25)\n",
    "        self.conv4_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ppg = nn.MaxPool1d(2)\n",
    "        self.relu4_ppg = nn.LeakyReLU()\n",
    "        self.bn2_ppg=nn.BatchNorm1d(5)\n",
    "        self.flat_ppg=nn.Flatten()\n",
    "        self.drop4_ppg=nn.Dropout(0.25)\n",
    "        self.linear1_ppg=nn.Linear(660,2)\n",
    "        self.softm_ppg=nn.Softmax()\n",
    "        \n",
    "        #centre\n",
    "        self.linear1_centre_ecg=nn.Conv1d(in_channels=1, out_channels=1, kernel_size=10, stride=1, padding='same')\n",
    "        self.linear1_centre_ppg=nn.Conv1d(in_channels=1, out_channels=1, kernel_size=10, stride=1, padding='same')\n",
    "        self.tanh1_ecg = nn.LeakyReLU()\n",
    "        self.tanh1_ppg = nn.LeakyReLU()\n",
    "        self.w1_centre=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        #self.w2_centre=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.bn1_centre=nn.BatchNorm1d(1)\n",
    "        self.conv1_centre = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_centre = nn.Sigmoid()\n",
    "        \n",
    "        self.alpha1=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.max1_centre = nn.MaxPool1d(2)\n",
    "        self.drop1_centre=nn.Dropout(0.25)\n",
    "        self.conv2_centre = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_centre = nn.MaxPool1d(2)\n",
    "        self.relu2_centre = nn.Sigmoid()\n",
    "        \n",
    "        self.alpha2=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.drop2_centre=nn.Dropout(0.25)\n",
    "        self.conv3_centre = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_centre=nn.Dropout(0.25)\n",
    "        self.conv4_centre = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_centre = nn.MaxPool1d(2)\n",
    "        self.relu4_centre = nn.Sigmoid()\n",
    "        \n",
    "        self.alpha3=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.bn2_centre=nn.BatchNorm1d(5)\n",
    "        self.flat_centre=nn.Flatten()\n",
    "        \n",
    "        self.alpha4=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.drop4_centre=nn.Dropout(0.25)\n",
    "        self.linear1_centre=nn.Linear(660,2)\n",
    "        self.softm_centre=nn.Softmax()\n",
    "        \n",
    "        #ecgsqi\n",
    "        self.bn1_ecgsqi=nn.BatchNorm1d(1)\n",
    "        self.conv1_ecgsqi = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ecgsqi = nn.LeakyReLU()\n",
    "        self.max1_ecgsqi = nn.MaxPool1d(2)\n",
    "        self.drop1_ecgsqi=nn.Dropout(0.25)\n",
    "        self.conv2_ecgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ecgsqi = nn.MaxPool1d(2)\n",
    "        self.relu2_ecgsqi = nn.LeakyReLU()\n",
    "        self.drop2_ecgsqi=nn.Dropout(0.25)\n",
    "        self.conv3_ecgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ecgsqi=nn.Dropout(0.25)\n",
    "        self.conv4_ecgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ecgsqi = nn.MaxPool1d(2)\n",
    "        self.relu4_ecgsqi = nn.LeakyReLU()\n",
    "        self.bn2_ecgsqi=nn.BatchNorm1d(5)\n",
    "        self.flat_ecgsqi=nn.Flatten()\n",
    "        \n",
    "        #ppgsqi\n",
    "        self.bn1_ppgsqi=nn.BatchNorm1d(1)\n",
    "        self.conv1_ppgsqi = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ppgsqi = nn.LeakyReLU()\n",
    "        self.max1_ppgsqi = nn.MaxPool1d(2)\n",
    "        self.drop1_ppgsqi=nn.Dropout(0.25)\n",
    "        self.conv2_ppgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ppgsqi = nn.MaxPool1d(2)\n",
    "        self.relu2_ppgsqi = nn.LeakyReLU()\n",
    "        self.drop2_ppgsqi=nn.Dropout(0.25)\n",
    "        self.conv3_ppgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ppgsqi=nn.Dropout(0.25)\n",
    "        self.conv4_ppgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ppgsqi = nn.MaxPool1d(2)\n",
    "        self.relu4_ppgsqi = nn.LeakyReLU()\n",
    "        self.bn2_ppgsqi=nn.BatchNorm1d(5)\n",
    "        self.flat_ppgsqi=nn.Flatten()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def forward(self, ecg, ppg, ecgsqi, ppgsqi):\n",
    "        \n",
    "        ### ecg\n",
    "        out_ecg_bn1=self.bn1_ecg(ecg)\n",
    "        out_ecg_conv1= self.conv1_ecg(out_ecg_bn1)\n",
    "        out_ecg_relu1 = self.relu1_ecg(out_ecg_conv1)\n",
    "        out_ecg_max1=self.max1_ecg(out_ecg_relu1)\n",
    "        out_ecg_drop1=self.drop1_ecg(out_ecg_max1)\n",
    "        out_ecg_conv2=self.conv2_ecg(out_ecg_drop1)\n",
    "        out_ecg_max2=self.max2_ecg(out_ecg_conv2)\n",
    "        out_ecg_relu2=self.relu2_ecg(out_ecg_max2)\n",
    "        out_ecg_drop2=self.drop2_ecg(out_ecg_relu2)\n",
    "        out_ecg_conv3=self.conv3_ecg(out_ecg_drop2)\n",
    "        out_ecg_drop3=self.drop3_ecg(out_ecg_conv3)\n",
    "        out_ecg_conv4=self.conv4_ecg(out_ecg_drop3)\n",
    "        out_ecg_max4=self.max4_ecg(out_ecg_conv4)\n",
    "        out_ecg_relu4=self.relu4_ecg(out_ecg_max4)\n",
    "        out_ecg_bn2=self.bn2_ecg(out_ecg_relu4)\n",
    "        out_ecg_flat=self.flat_ecg(out_ecg_bn2)\n",
    "        out_ecg_drop4=self.drop4_ecg(out_ecg_flat)\n",
    "        out_ecg_linear=self.linear1_ecg(out_ecg_drop4)\n",
    "        out_ecg_softm=self.softm_ecg(out_ecg_linear)\n",
    "        \n",
    "        ### ppg\n",
    "        out_ppg_bn1=self.bn1_ppg(ppg)\n",
    "        out_ppg_conv1= self.conv1_ppg(out_ppg_bn1)\n",
    "        out_ppg_relu1 = self.relu1_ppg(out_ppg_conv1)\n",
    "        out_ppg_max1=self.max1_ppg(out_ppg_relu1)\n",
    "        out_ppg_drop1=self.drop1_ppg(out_ppg_max1)\n",
    "        out_ppg_conv2=self.conv2_ppg(out_ppg_drop1)\n",
    "        out_ppg_max2=self.max2_ppg(out_ppg_conv2)\n",
    "        out_ppg_relu2=self.relu2_ppg(out_ppg_max2)\n",
    "        out_ppg_drop2=self.drop2_ppg(out_ppg_relu2)\n",
    "        out_ppg_conv3=self.conv3_ppg(out_ppg_drop2)\n",
    "        out_ppg_drop3=self.drop3_ppg(out_ppg_conv3)\n",
    "        out_ppg_conv4=self.conv4_ppg(out_ppg_drop3)\n",
    "        out_ppg_max4=self.max4_ppg(out_ppg_conv4)\n",
    "        out_ppg_relu4=self.relu4_ppg(out_ppg_max4)\n",
    "        out_ppg_bn2=self.bn2_ppg(out_ppg_relu4)\n",
    "        out_ppg_flat=self.flat_ppg(out_ppg_bn2)\n",
    "        out_ppg_drop4=self.drop4_ppg(out_ppg_flat)\n",
    "        out_ppg_linear=self.linear1_ppg(out_ppg_drop4)\n",
    "        out_ppg_softm=self.softm_ppg(out_ppg_linear)\n",
    "        \n",
    "        \n",
    "        ### ecgsqi\n",
    "        out_ecgsqi_bn1=self.bn1_ecgsqi(ecgsqi)\n",
    "        out_ecgsqi_conv1= self.conv1_ecgsqi(out_ecgsqi_bn1)\n",
    "        out_ecgsqi_relu1 = self.relu1_ecgsqi(out_ecgsqi_conv1)\n",
    "        out_ecgsqi_max1=self.max1_ecgsqi(out_ecgsqi_relu1)\n",
    "        out_ecgsqi_drop1=self.drop1_ecgsqi(out_ecgsqi_max1)\n",
    "        out_ecgsqi_conv2=self.conv2_ecgsqi(out_ecgsqi_drop1)\n",
    "        out_ecgsqi_max2=self.max2_ecgsqi(out_ecgsqi_conv2)\n",
    "        out_ecgsqi_relu2=self.relu2_ecgsqi(out_ecgsqi_max2)\n",
    "        out_ecgsqi_drop2=self.drop2_ecgsqi(out_ecgsqi_relu2)\n",
    "        out_ecgsqi_conv3=self.conv3_ecgsqi(out_ecgsqi_drop2)\n",
    "        out_ecgsqi_drop3=self.drop3_ecgsqi(out_ecgsqi_conv3)\n",
    "        out_ecgsqi_conv4=self.conv4_ecgsqi(out_ecgsqi_drop3)\n",
    "        out_ecgsqi_max4=self.max4_ecgsqi(out_ecgsqi_conv4)\n",
    "        out_ecgsqi_relu4=self.relu4_ecgsqi(out_ecgsqi_max4)\n",
    "        out_ecgsqi_bn2=self.bn2_ecgsqi(out_ecgsqi_relu4)\n",
    "        out_ecgsqi_flat=self.flat_ecgsqi(out_ecgsqi_bn2)\n",
    "\n",
    "        ### ppgsqi\n",
    "        out_ppgsqi_bn1=self.bn1_ppgsqi(ppgsqi)\n",
    "        out_ppgsqi_conv1= self.conv1_ppgsqi(out_ppgsqi_bn1)\n",
    "        out_ppgsqi_relu1 = self.relu1_ppgsqi(out_ppgsqi_conv1)\n",
    "        out_ppgsqi_max1=self.max1_ppgsqi(out_ppgsqi_relu1)\n",
    "        out_ppgsqi_drop1=self.drop1_ppgsqi(out_ppgsqi_max1)\n",
    "        out_ppgsqi_conv2=self.conv2_ppgsqi(out_ppgsqi_drop1)\n",
    "        out_ppgsqi_max2=self.max2_ppgsqi(out_ppgsqi_conv2)\n",
    "        out_ppgsqi_relu2=self.relu2_ppgsqi(out_ppgsqi_max2)\n",
    "        out_ppgsqi_drop2=self.drop2_ppgsqi(out_ppgsqi_relu2)\n",
    "        out_ppgsqi_conv3=self.conv3_ppgsqi(out_ppgsqi_drop2)\n",
    "        out_ppgsqi_drop3=self.drop3_ppgsqi(out_ppgsqi_conv3)\n",
    "        out_ppgsqi_conv4=self.conv4_ppgsqi(out_ppgsqi_drop3)\n",
    "        out_ppgsqi_max4=self.max4_ppgsqi(out_ppgsqi_conv4)\n",
    "        out_ppgsqi_relu4=self.relu4_ppgsqi(out_ppgsqi_max4)\n",
    "        out_ppgsqi_bn2=self.bn2_ppgsqi(out_ppgsqi_relu4)\n",
    "        out_ppgsqi_flat=self.flat_ppgsqi(out_ppgsqi_bn2)\n",
    "        \n",
    "        ####weighted_sqis\n",
    "        out_ecgsqi_relu1_w=out_ecgsqi_relu1.div(out_ecgsqi_relu1+out_ppgsqi_relu1+1e-6)\n",
    "        out_ppgsqi_relu1_w=out_ppgsqi_relu1.div(out_ecgsqi_relu1+out_ppgsqi_relu1+1e-6)\n",
    "        \n",
    "        out_ecgsqi_relu2_w=out_ecgsqi_relu2.div(out_ecgsqi_relu2+out_ppgsqi_relu2+1e-6)\n",
    "        out_ppgsqi_relu2_w=out_ppgsqi_relu2.div(out_ecgsqi_relu2+out_ppgsqi_relu2+1e-6)\n",
    "        \n",
    "        out_ecgsqi_relu4_w=out_ecgsqi_relu4.div(out_ecgsqi_relu4+out_ppgsqi_relu4+1e-6)\n",
    "        out_ppgsqi_relu4_w=out_ppgsqi_relu4.div(out_ecgsqi_relu4+out_ppgsqi_relu4+1e-6)\n",
    "        \n",
    "        out_ecgsqi_flat_w=out_ecgsqi_flat.div(out_ecgsqi_flat+out_ppgsqi_flat+1e-6)\n",
    "        out_ppgsqi_flat_w=out_ppgsqi_flat.div(out_ecgsqi_flat+out_ppgsqi_flat+1e-6)\n",
    "        \n",
    "        ### centre\n",
    "        \n",
    "        out_centre_ecg=self.linear1_centre_ecg(ecg)\n",
    "        out_centre_ppg=self.linear1_centre_ppg(ppg)\n",
    "        out_centre_ecg=self.tanh1_ecg(out_centre_ecg)\n",
    "        out_centre_ppg=self.tanh1_ecg(out_centre_ppg)\n",
    "        \n",
    "        \n",
    "        out_init=torch.mul(out_centre_ecg,self.w1_centre)+torch.mul(out_centre_ppg,1-self.w1_centre)\n",
    "        \n",
    "        out_centre_bn1=self.bn1_centre(out_init)\n",
    "        out_centre_conv1=self.conv1_centre(out_centre_bn1)\n",
    "        out_centre_relu1=self.relu1_centre(out_centre_conv1)\n",
    "        \n",
    "        out_hidden_1=torch.mul(out_centre_relu1,self.alpha1)+torch.mul((torch.mul(out_ecgsqi_relu1_w,out_ecg_relu1))+(torch.mul(out_ppgsqi_relu1_w,out_ppg_relu1)),(1-self.alpha1))\n",
    "        \n",
    "        out_centre_max1=self.max1_centre(out_hidden_1)\n",
    "        out_centre_drop1=self.drop1_centre(out_centre_max1)\n",
    "        out_centre_conv2=self.conv2_centre(out_centre_drop1)\n",
    "        out_centre_max2=self.max2_centre(out_centre_conv2)\n",
    "        out_centre_relu2=self.relu2_centre(out_centre_max2)\n",
    "                                                                        \n",
    "        out_hidden_2=torch.mul(out_centre_relu2,self.alpha2)+torch.mul((torch.mul(out_ecgsqi_relu2_w,out_ecg_relu2))+(torch.mul(out_ppgsqi_relu2_w,out_ppg_relu2)),(1-self.alpha2))\n",
    "        ################\n",
    "        out_centre_drop2=self.drop2_centre(out_hidden_2)\n",
    "        out_centre_conv3=self.conv3_centre(out_centre_drop2)\n",
    "        out_centre_drop3=self.drop3_centre(out_centre_conv3)\n",
    "        out_centre_conv4=self.conv4_centre(out_centre_drop3)\n",
    "        out_centre_max4=self.max4_centre(out_centre_conv4)\n",
    "        out_centre_relu4=self.relu4_centre(out_centre_max4)\n",
    "                                                                        \n",
    "        out_hidden_3=torch.mul(out_centre_relu4,self.alpha3)+torch.mul((torch.mul(out_ecgsqi_relu4_w,out_ecg_relu4))+(torch.mul(out_ppgsqi_relu4_w,out_ppg_relu4)),(1-self.alpha3))                                                                \n",
    "        \n",
    "        out_centre_bn2=self.bn2_centre(out_hidden_3)\n",
    "        out_centre_flatten=self.flat_centre(out_centre_bn2)\n",
    "                                                                        \n",
    "        out_hidden_4= torch.mul(out_centre_flatten,self.alpha4)+torch.mul((torch.mul(out_ecgsqi_flat_w,out_ecg_flat))+(torch.mul(out_ppgsqi_flat_w,out_ppg_flat)),(1-self.alpha4))                                                                \n",
    "                                                                       \n",
    "        out_centre_drop4=self.drop4_centre(out_hidden_4)\n",
    "        out_centre_linear=self.linear1_centre(out_centre_drop4)\n",
    "        out_centre_softm=self.softm_centre(out_centre_linear)\n",
    "\n",
    "        return out_centre_softm, out_ppg_softm, out_ecg_softm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6458df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889a1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fusion = fusion_model_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b9b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ecg_train = torch.from_numpy(ecg_train)\n",
    "ecg_valid=torch.from_numpy(ecg_valid)\n",
    "ecg_test=torch.from_numpy(ecg_test)\n",
    "\n",
    "ppg_train = torch.from_numpy(ppg_train)\n",
    "ppg_valid=torch.from_numpy(ppg_valid)\n",
    "ppg_test = torch.from_numpy(ppg_test)\n",
    "\n",
    "ecg_sqi_train = torch.from_numpy(ecg_sqi_train)\n",
    "ecg_sqi_valid=torch.from_numpy(ecg_sqi_valid)\n",
    "ecg_sqi_test = torch.from_numpy(ecg_sqi_test)\n",
    "\n",
    "ppg_sqi_train = torch.from_numpy(ppg_sqi_train)\n",
    "ppg_sqi_valid=torch.from_numpy(ppg_sqi_valid)\n",
    "ppg_sqi_test = torch.from_numpy(ppg_sqi_test)\n",
    "\n",
    "y_train_wide = torch.from_numpy(y_train_wide)\n",
    "y_valid_wide = torch.from_numpy(y_valid_wide)\n",
    "y_test_wide = torch.from_numpy(y_test_wide)\n",
    "y_train_num = torch.from_numpy(y_train_num)\n",
    "y_valid_num = torch.from_numpy(y_valid_num)\n",
    "y_test_num = torch.from_numpy(y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "170fe69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_fusion = model_fusion.cuda()\n",
    "#if torch.cuda.is_available():\n",
    "#    ecg_valid, y_valid_num, ppg_valid, ecg_sqi_valid, ppg_sqi_valid = ecg_valid.cuda(), y_valid_num.cuda(), ppg_valid.cuda(), ecg_sqi_valid.cuda(), ppg_sqi_valid.cuda()\n",
    "    #ecg_train, y_train_num, ppg_train, ecg_sqi_train, ppg_sqi_train = ecg_train.cuda(), y_train_num.cuda(), ppg_train.cuda(), ecg_sqi_train.cuda(), ppg_sqi_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ea716c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\torch\\nn\\modules\\conv.py:295: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\\aten\\src\\ATen\\native\\Convolution.cpp:660.)\n",
      "  self.padding, self.dilation, self.groups)\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.7415015825483584 \t \t Accuracy = 55.79151153564453, \t Validation Loss: 0.6538472639189826, \t Validation accuracy: 62.31790542602539\n",
      "Validation Loss Decreased(inf--->0.653847) \t Saving The Model\n",
      "Starting epoch 2\n",
      "Epoch 2 \t\t Training Loss: 0.6911732468305898 \t \t Accuracy = 61.3421745300293, \t Validation Loss: 0.6223917481494926, \t Validation accuracy: 68.27420043945312\n",
      "Validation Loss Decreased(0.653847--->0.622392) \t Saving The Model\n",
      "Starting epoch 3\n",
      "Epoch 3 \t\t Training Loss: 0.6161032403027988 \t \t Accuracy = 73.08454895019531, \t Validation Loss: 0.5515795716068201, \t Validation accuracy: 73.86043548583984\n",
      "Validation Loss Decreased(0.622392--->0.551580) \t Saving The Model\n",
      "Starting epoch 4\n",
      "Epoch 4 \t\t Training Loss: 0.5957378146721792 \t \t Accuracy = 73.03755187988281, \t Validation Loss: 0.5376765145892985, \t Validation accuracy: 74.78853607177734\n",
      "Validation Loss Decreased(0.551580--->0.537677) \t Saving The Model\n",
      "Starting epoch 5\n",
      "Epoch 5 \t\t Training Loss: 0.5671694501814314 \t \t Accuracy = 77.4280014038086, \t Validation Loss: 0.5161798739293862, \t Validation accuracy: 78.68891143798828\n",
      "Validation Loss Decreased(0.537677--->0.516180) \t Saving The Model\n",
      "Starting epoch 6\n",
      "Epoch 6 \t\t Training Loss: 0.5524039568967725 \t \t Accuracy = 80.3990249633789, \t Validation Loss: 0.5066167551871629, \t Validation accuracy: 80.65084838867188\n",
      "Validation Loss Decreased(0.516180--->0.506617) \t Saving The Model\n",
      "Starting epoch 7\n",
      "Epoch 7 \t\t Training Loss: 0.5451515012777838 \t \t Accuracy = 81.16564178466797, \t Validation Loss: 0.5033703094337418, \t Validation accuracy: 81.09727478027344\n",
      "Validation Loss Decreased(0.506617--->0.503370) \t Saving The Model\n",
      "Starting epoch 8\n",
      "Epoch 8 \t\t Training Loss: 0.5409660038111129 \t \t Accuracy = 81.54161071777344, \t Validation Loss: 0.497973529741778, \t Validation accuracy: 81.27349853515625\n",
      "Validation Loss Decreased(0.503370--->0.497974) \t Saving The Model\n",
      "Starting epoch 9\n",
      "Epoch 9 \t\t Training Loss: 0.5375170783678952 \t \t Accuracy = 81.78760528564453, \t Validation Loss: 0.4955704386471308, \t Validation accuracy: 81.96663665771484\n",
      "Validation Loss Decreased(0.497974--->0.495570) \t Saving The Model\n",
      "Starting epoch 10\n",
      "Epoch 10 \t\t Training Loss: 0.5327014865465742 \t \t Accuracy = 82.2671127319336, \t Validation Loss: 0.4900838229042745, \t Validation accuracy: 82.0782470703125\n",
      "Validation Loss Decreased(0.495570--->0.490084) \t Saving The Model\n",
      "Starting epoch 11\n",
      "Epoch 11 \t\t Training Loss: 0.5291071866772005 \t \t Accuracy = 82.58506774902344, \t Validation Loss: 0.4877679668671904, \t Validation accuracy: 82.63628387451172\n",
      "Validation Loss Decreased(0.490084--->0.487768) \t Saving The Model\n",
      "Starting epoch 12\n",
      "Epoch 12 \t\t Training Loss: 0.5258766623157868 \t \t Accuracy = 83.01464080810547, \t Validation Loss: 0.4859369942667889, \t Validation accuracy: 82.712646484375\n",
      "Validation Loss Decreased(0.487768--->0.485937) \t Saving The Model\n",
      "Starting epoch 13\n",
      "Epoch 13 \t\t Training Loss: 0.524570311538707 \t \t Accuracy = 83.04180908203125, \t Validation Loss: 0.48416071851351106, \t Validation accuracy: 82.78900909423828\n",
      "Validation Loss Decreased(0.485937--->0.484161) \t Saving The Model\n",
      "Starting epoch 14\n",
      "Epoch 14 \t\t Training Loss: 0.5225861745963531 \t \t Accuracy = 83.16444396972656, \t Validation Loss: 0.4818332270223495, \t Validation accuracy: 83.02983856201172\n",
      "Validation Loss Decreased(0.484161--->0.481833) \t Saving The Model\n",
      "Starting epoch 15\n",
      "Epoch 15 \t\t Training Loss: 0.5204066927509761 \t \t Accuracy = 83.44274139404297, \t Validation Loss: 0.4787249373413666, \t Validation accuracy: 83.42340087890625\n",
      "Validation Loss Decreased(0.481833--->0.478725) \t Saving The Model\n",
      "Starting epoch 16\n",
      "Epoch 16 \t\t Training Loss: 0.5181191015456404 \t \t Accuracy = 83.64981842041016, \t Validation Loss: 0.47807396416775666, \t Validation accuracy: 83.4468994140625\n",
      "Validation Loss Decreased(0.478725--->0.478074) \t Saving The Model\n",
      "Starting epoch 17\n",
      "Epoch 17 \t\t Training Loss: 0.515865625330436 \t \t Accuracy = 83.92372131347656, \t Validation Loss: 0.474439824708024, \t Validation accuracy: 84.081298828125\n",
      "Validation Loss Decreased(0.478074--->0.474440) \t Saving The Model\n",
      "Starting epoch 18\n",
      "Epoch 18 \t\t Training Loss: 0.5142094736806768 \t \t Accuracy = 84.10362243652344, \t Validation Loss: 0.4717298082092352, \t Validation accuracy: 84.13416290283203\n",
      "Validation Loss Decreased(0.474440--->0.471730) \t Saving The Model\n",
      "Starting epoch 19\n",
      "Epoch 19 \t\t Training Loss: 0.5115265227518135 \t \t Accuracy = 84.39881896972656, \t Validation Loss: 0.46955068540154843, \t Validation accuracy: 84.46898651123047\n",
      "Validation Loss Decreased(0.471730--->0.469551) \t Saving The Model\n",
      "Starting epoch 20\n",
      "Epoch 20 \t\t Training Loss: 0.5086574764025951 \t \t Accuracy = 84.64921569824219, \t Validation Loss: 0.468472270066278, \t Validation accuracy: 84.74507141113281\n",
      "Validation Loss Decreased(0.469551--->0.468472) \t Saving The Model\n",
      "Starting epoch 21\n",
      "Epoch 21 \t\t Training Loss: 0.5051055974642137 \t \t Accuracy = 84.99801635742188, \t Validation Loss: 0.46503410318441557, \t Validation accuracy: 84.93303680419922\n",
      "Validation Loss Decreased(0.468472--->0.465034) \t Saving The Model\n",
      "Starting epoch 22\n",
      "Epoch 22 \t\t Training Loss: 0.5023704533626262 \t \t Accuracy = 85.26530456542969, \t Validation Loss: 0.46508310482515924, \t Validation accuracy: 84.91541290283203\n",
      "Starting epoch 23\n",
      "Epoch 23 \t\t Training Loss: 0.5002320911665272 \t \t Accuracy = 85.48633575439453, \t Validation Loss: 0.4640791196572153, \t Validation accuracy: 85.19737243652344\n",
      "Validation Loss Decreased(0.465034--->0.464079) \t Saving The Model\n",
      "Starting epoch 24\n",
      "Epoch 24 \t\t Training Loss: 0.4987394828349352 \t \t Accuracy = 85.59794616699219, \t Validation Loss: 0.45645914614549155, \t Validation accuracy: 85.74365997314453\n",
      "Validation Loss Decreased(0.464079--->0.456459) \t Saving The Model\n",
      "Starting epoch 25\n",
      "Epoch 25 \t\t Training Loss: 0.49782943427282617 \t \t Accuracy = 85.70001983642578, \t Validation Loss: 0.4784555314925679, \t Validation accuracy: 83.51738739013672\n",
      "Starting epoch 26\n",
      "Epoch 26 \t\t Training Loss: 0.49819125665029634 \t \t Accuracy = 85.65962982177734, \t Validation Loss: 0.4566274827335313, \t Validation accuracy: 85.80827331542969\n",
      "Starting epoch 27\n",
      "Epoch 27 \t\t Training Loss: 0.4961676421764314 \t \t Accuracy = 85.86964416503906, \t Validation Loss: 0.45978358213664494, \t Validation accuracy: 85.5556869506836\n",
      "Starting epoch 28\n",
      "Epoch 28 \t\t Training Loss: 0.4949595885197247 \t \t Accuracy = 85.9981460571289, \t Validation Loss: 0.4538991988053796, \t Validation accuracy: 86.06673431396484\n",
      "Validation Loss Decreased(0.456459--->0.453899) \t Saving The Model\n",
      "Starting epoch 29\n",
      "Epoch 29 \t\t Training Loss: 0.4939722528092955 \t \t Accuracy = 86.08112335205078, \t Validation Loss: 0.46304541617109063, \t Validation accuracy: 84.98590087890625\n",
      "Starting epoch 30\n",
      "Epoch 30 \t\t Training Loss: 0.49539586223129717 \t \t Accuracy = 85.91297149658203, \t Validation Loss: 0.4625335421129974, \t Validation accuracy: 85.17974853515625\n",
      "Starting epoch 31\n",
      "Epoch 31 \t\t Training Loss: 0.49644117510380376 \t \t Accuracy = 85.83439636230469, \t Validation Loss: 0.45443114063196016, \t Validation accuracy: 85.96099853515625\n",
      "Starting epoch 32\n",
      "Epoch 32 \t\t Training Loss: 0.4915624728804468 \t \t Accuracy = 86.28673553466797, \t Validation Loss: 0.452388838717812, \t Validation accuracy: 86.20183563232422\n",
      "Validation Loss Decreased(0.453899--->0.452389) \t Saving The Model\n",
      "Starting epoch 33\n",
      "Epoch 33 \t\t Training Loss: 0.491483148649559 \t \t Accuracy = 86.27204895019531, \t Validation Loss: 0.4545081153250577, \t Validation accuracy: 85.80827331542969\n",
      "Starting epoch 34\n",
      "Epoch 34 \t\t Training Loss: 0.48857896873741447 \t \t Accuracy = 86.58853149414062, \t Validation Loss: 0.4509909830943883, \t Validation accuracy: 86.3193130493164\n",
      "Validation Loss Decreased(0.452389--->0.450991) \t Saving The Model\n",
      "Starting epoch 35\n",
      "Epoch 35 \t\t Training Loss: 0.48543120577539267 \t \t Accuracy = 86.88960266113281, \t Validation Loss: 0.44228992266961703, \t Validation accuracy: 87.15343475341797\n",
      "Validation Loss Decreased(0.450991--->0.442290) \t Saving The Model\n",
      "Starting epoch 36\n",
      "Epoch 36 \t\t Training Loss: 0.48423262160355435 \t \t Accuracy = 87.0122299194336, \t Validation Loss: 0.44407755711622404, \t Validation accuracy: 87.02420043945312\n",
      "Starting epoch 37\n",
      "Epoch 37 \t\t Training Loss: 0.48348225325458033 \t \t Accuracy = 87.11283111572266, \t Validation Loss: 0.4457964532905155, \t Validation accuracy: 86.68350982666016\n",
      "Starting epoch 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 \t\t Training Loss: 0.48185174232278777 \t \t Accuracy = 87.24280548095703, \t Validation Loss: 0.4424210985501607, \t Validation accuracy: 86.90084838867188\n",
      "Starting epoch 39\n",
      "Epoch 39 \t\t Training Loss: 0.47996485929347965 \t \t Accuracy = 87.40068054199219, \t Validation Loss: 0.4457903997591364, \t Validation accuracy: 86.81861114501953\n",
      "Starting epoch 40\n",
      "Epoch 40 \t\t Training Loss: 0.4789702353116713 \t \t Accuracy = 87.51963806152344, \t Validation Loss: 0.43982692402705814, \t Validation accuracy: 87.37077331542969\n",
      "Validation Loss Decreased(0.442290--->0.439827) \t Saving The Model\n",
      "Starting epoch 41\n",
      "Epoch 41 \t\t Training Loss: 0.47788442611778364 \t \t Accuracy = 87.59527587890625, \t Validation Loss: 0.43722153041097855, \t Validation accuracy: 87.55287170410156\n",
      "Validation Loss Decreased(0.439827--->0.437222) \t Saving The Model\n",
      "Starting epoch 42\n",
      "Epoch 42 \t\t Training Loss: 0.4746900041398585 \t \t Accuracy = 87.951416015625, \t Validation Loss: 0.4341245021736413, \t Validation accuracy: 87.72908782958984\n",
      "Validation Loss Decreased(0.437222--->0.434125) \t Saving The Model\n",
      "Starting epoch 43\n",
      "Epoch 43 \t\t Training Loss: 0.47355802191939567 \t \t Accuracy = 88.06670379638672, \t Validation Loss: 0.43887749157453837, \t Validation accuracy: 87.51174926757812\n",
      "Starting epoch 44\n",
      "Epoch 44 \t\t Training Loss: 0.47507980500200864 \t \t Accuracy = 87.87945556640625, \t Validation Loss: 0.43655286093204343, \t Validation accuracy: 87.62923431396484\n",
      "Starting epoch 45\n",
      "Epoch 45 \t\t Training Loss: 0.4741929555381823 \t \t Accuracy = 87.98078918457031, \t Validation Loss: 0.4355558129081949, \t Validation accuracy: 87.89356231689453\n",
      "Starting epoch 46\n",
      "Epoch 46 \t\t Training Loss: 0.4728762679978421 \t \t Accuracy = 88.09093475341797, \t Validation Loss: 0.44010207754129554, \t Validation accuracy: 87.44713592529297\n",
      "Starting epoch 47\n",
      "Epoch 47 \t\t Training Loss: 0.4738861765376383 \t \t Accuracy = 88.0064926147461, \t Validation Loss: 0.43774820977484274, \t Validation accuracy: 87.61161041259766\n",
      "Starting epoch 48\n",
      "Epoch 48 \t\t Training Loss: 0.4723097100937949 \t \t Accuracy = 88.14820861816406, \t Validation Loss: 0.4315770986484505, \t Validation accuracy: 88.14614868164062\n",
      "Validation Loss Decreased(0.434125--->0.431577) \t Saving The Model\n",
      "Starting epoch 49\n",
      "Epoch 49 \t\t Training Loss: 0.4711768389294358 \t \t Accuracy = 88.28038787841797, \t Validation Loss: 0.4373232528828738, \t Validation accuracy: 87.62335968017578\n",
      "Starting epoch 50\n",
      "Epoch 50 \t\t Training Loss: 0.4745020535249347 \t \t Accuracy = 87.97197723388672, \t Validation Loss: 0.436672480134239, \t Validation accuracy: 87.57636260986328\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "#loss_function = nn.functional.binary_cross_entropy\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_fusion.parameters(), lr=1.5e-5)\n",
    "batch_size=32\n",
    "n_batches=np.ceil(len(ecg_train)/batch_size).astype(np.int64)\n",
    "valid_batch_size=100\n",
    "valid_batches=np.ceil(len(ecg_valid)/valid_batch_size).astype(np.int64) \n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(0, 50): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    current_tot_loss=0.0\n",
    "    correct=0\n",
    "    i=0\n",
    "    # Iterate over the DataLoader for training data\n",
    "    ind_list = list(range(len(ecg_train)))\n",
    "    shuffle(ind_list)\n",
    "    #train_new  = train[ind_list, :,:,:]\n",
    "    #target_new = target[ind_list,]\n",
    "    while i<n_batches:\n",
    "\n",
    "          # Get inputs\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_wide[i*batch_size:(i+1)*batch_size,]\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_num[i*batch_size:(i+1)*batch_size,]\n",
    "        local_ecg, local_y, local_ppg, local_ecg_sqi,local_ppg_sqi = ecg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),y_train_num[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ppg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ecg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),ppg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda()\n",
    "        #if torch.cuda.is_available():\n",
    "        #    local_X, local_y = local_X.cuda(), local_y.cuda()\n",
    "\n",
    "          # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs_c, outputs_ecg, outputs_ppg = model_fusion(local_ecg.float(),local_ppg.float(),local_ecg_sqi.float(), local_ppg_sqi.float())\n",
    "        \n",
    "        \n",
    "\n",
    "        # Compute loss\n",
    "        loss1 = loss_function(outputs_c, local_y)\n",
    "        #loss2 = loss_function(outputs_ecg, local_y)\n",
    "        #loss3 = loss_function(outputs_ppg, local_y)\n",
    "        #loss=(loss1+loss2+loss3)/3\n",
    "        loss=loss1\n",
    "        #print(loss)\n",
    "        \n",
    "        #loss = loss_function(outputs, local_y.float())\n",
    "        l2_lambda = 0.001\n",
    "        l2_reg = torch.tensor(0.).cuda()\n",
    "        for param in model_fusion.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += l2_lambda * l2_reg\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        output = outputs_c.clone()\n",
    "        output= torch.argmax(output, axis=1)\n",
    "        \n",
    "        correct += (output == local_y).float().sum()\n",
    "\n",
    "        # Print statistics\n",
    "        \n",
    "        #current_loss += loss.item()\n",
    "        current_tot_loss+=loss.item()\n",
    "       # if i % 20 == 19:\n",
    "       #     print('Loss after mini-batch %5d: %.3f' %\n",
    "       #         (i + 1, current_loss / 20))\n",
    "       #     current_loss = 0.0\n",
    "        i=i+1\n",
    "        \n",
    "    \n",
    "    \n",
    "    correct_valid=0\n",
    "    current_valid_loss = 0.0\n",
    "    current_valid_tot_loss=0.0\n",
    "    j=0\n",
    "    while j<valid_batches:\n",
    "        model_fusion.eval()     # Optional when not using Model Specific layer\n",
    "        local_ecg_valid, local_y_valid, local_ppg_valid, local_ecg_sqi_valid,local_ppg_sqi_valid = ecg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),y_valid_num[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ppg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ecg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),ppg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda()\n",
    "        target, target2, target3 = model_fusion(local_ecg_valid.float(),local_ppg_valid.float(),local_ecg_sqi_valid.float(), local_ppg_sqi_valid.float())\n",
    "        loss1 = loss_function(target,local_y_valid)\n",
    "        #loss2 = loss_function(target2,local_y_valid)\n",
    "        #loss3 = loss_function(target3,local_y_valid)\n",
    "        loss=loss1\n",
    "        #loss=(loss1+loss2+loss3)/3\n",
    "        current_valid_loss+=loss.item()\n",
    "        #valid_loss = loss.item() \n",
    "        target= torch.argmax(target, axis=1)\n",
    "        correct_valid += (target == local_y_valid).float().sum()\n",
    "        j=j+1\n",
    "    \n",
    "    #print(correct)\n",
    "    #print(current_tot_loss)\n",
    "    accuracy = 100 * correct / len(ecg_train)\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {current_tot_loss / n_batches} \\t \\t Accuracy = {accuracy}, \\t Validation Loss: {current_valid_loss/ valid_batches}, \\t Validation accuracy: {100*correct_valid/len(ecg_valid)}')\n",
    "    \n",
    "    if min_valid_loss > (current_valid_loss/valid_batches):\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{current_valid_loss/valid_batches:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = (current_valid_loss/valid_batches)\n",
    "        # Saving State Dict\n",
    "        torch.save(model_fusion.state_dict(), 'saved_model_fusion_noise_0.01_2_-20.pth')\n",
    "        \n",
    "        \n",
    "    \n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a1f0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fusion_model_v3(\n",
       "  (bn1_ecg): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ecg): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ecg): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ecg): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ecg): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ecg): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ecg): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_ecg): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_ecg): Softmax(dim=None)\n",
       "  (bn1_ppg): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ppg): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ppg): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ppg): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ppg): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ppg): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ppg): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_ppg): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_ppg): Softmax(dim=None)\n",
       "  (linear1_centre_ecg): Conv1d(1, 1, kernel_size=(10,), stride=(1,), padding=same)\n",
       "  (linear1_centre_ppg): Conv1d(1, 1, kernel_size=(10,), stride=(1,), padding=same)\n",
       "  (tanh1_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (tanh1_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn1_centre): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_centre): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_centre): Sigmoid()\n",
       "  (max1_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_centre): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_centre): Sigmoid()\n",
       "  (drop2_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_centre): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_centre): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_centre): Sigmoid()\n",
       "  (bn2_centre): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_centre): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_centre): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_centre): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_centre): Softmax(dim=None)\n",
       "  (bn1_ecgsqi): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ecgsqi): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ecgsqi): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ecgsqi): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ecgsqi): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ecgsqi): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ecgsqi): Flatten(start_dim=1, end_dim=-1)\n",
       "  (bn1_ppgsqi): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ppgsqi): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ppgsqi): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ppgsqi): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ppgsqi): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ppgsqi): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ppgsqi): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_saved = fusion_model_v3()\n",
    "model_saved.load_state_dict(torch.load('saved_model_fusion_noise_0.01_2_-20.pth'))\n",
    "model_saved.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85706149",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved=model_saved.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e8b2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centre output\n",
      "tensor(0.8809)\n",
      "[[6945 1566]\n",
      " [  96 5352]]\n"
     ]
    }
   ],
   "source": [
    "outputs_test,out1,out2 = model_saved(ecg_test.float(), ppg_test.float(), ecg_sqi_test.float(), ppg_sqi_test.float())\n",
    "outputs_test = outputs_test.clone()\n",
    "outputs_test= torch.argmax(outputs_test, axis=1)\n",
    "\n",
    "print(\"centre output\")\n",
    "        \n",
    "correct = (outputs_test == y_test_num).float().sum()\n",
    "print(correct/len(ecg_test))\n",
    "\n",
    "cm=confusion_matrix(y_test_num.cpu(), outputs_test.cpu())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d82599",
   "metadata": {},
   "source": [
    "## combining losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bde66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91db8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fusion2 = fusion_model_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91992775",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_fusion2 = model_fusion2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a5c83df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 1.1502048708918624 \t \t Accuracy = 55.41554641723633, \t Validation Loss: 0.6418115907942342, \t Validation accuracy: 56.91376876831055\n",
      "Validation Loss Decreased(inf--->0.641812) \t Saving The Model\n",
      "Starting epoch 2\n",
      "Epoch 2 \t\t Training Loss: 0.9757166264676734 \t \t Accuracy = 78.40316772460938, \t Validation Loss: 0.5059153761780053, \t Validation accuracy: 82.99459838867188\n",
      "Validation Loss Decreased(0.641812--->0.505915) \t Saving The Model\n",
      "Starting epoch 3\n",
      "Epoch 3 \t\t Training Loss: 0.8926639360816855 \t \t Accuracy = 83.24007415771484, \t Validation Loss: 0.48943646870858487, \t Validation accuracy: 83.63487243652344\n",
      "Validation Loss Decreased(0.505915--->0.489436) \t Saving The Model\n",
      "Starting epoch 4\n",
      "Epoch 4 \t\t Training Loss: 0.8614227798228201 \t \t Accuracy = 84.25636291503906, \t Validation Loss: 0.4800009087860933, \t Validation accuracy: 84.92716217041016\n",
      "Validation Loss Decreased(0.489436--->0.480001) \t Saving The Model\n",
      "Starting epoch 5\n",
      "Epoch 5 \t\t Training Loss: 0.842233923943083 \t \t Accuracy = 84.2049560546875, \t Validation Loss: 0.47777593066120705, \t Validation accuracy: 84.62171173095703\n",
      "Validation Loss Decreased(0.480001--->0.477776) \t Saving The Model\n",
      "Starting epoch 6\n",
      "Epoch 6 \t\t Training Loss: 0.8272734098416522 \t \t Accuracy = 84.99140930175781, \t Validation Loss: 0.4757240977552202, \t Validation accuracy: 85.33247375488281\n",
      "Validation Loss Decreased(0.477776--->0.475724) \t Saving The Model\n",
      "Starting epoch 7\n",
      "Epoch 7 \t\t Training Loss: 0.8160506169542783 \t \t Accuracy = 85.17278289794922, \t Validation Loss: 0.47533288127497625, \t Validation accuracy: 85.47932434082031\n",
      "Validation Loss Decreased(0.475724--->0.475333) \t Saving The Model\n",
      "Starting epoch 8\n",
      "Epoch 8 \t\t Training Loss: 0.8048462969552082 \t \t Accuracy = 85.37765502929688, \t Validation Loss: 0.4748342127827873, \t Validation accuracy: 85.64967346191406\n",
      "Validation Loss Decreased(0.475333--->0.474834) \t Saving The Model\n",
      "Starting epoch 9\n",
      "Epoch 9 \t\t Training Loss: 0.7974874814061966 \t \t Accuracy = 84.84968566894531, \t Validation Loss: 0.49281607298125996, \t Validation accuracy: 79.55827331542969\n",
      "Starting epoch 10\n",
      "Epoch 10 \t\t Training Loss: 0.8071243442258889 \t \t Accuracy = 80.42546081542969, \t Validation Loss: 0.4886488795977587, \t Validation accuracy: 81.27349853515625\n",
      "Starting epoch 11\n",
      "Epoch 11 \t\t Training Loss: 0.7969790819640222 \t \t Accuracy = 81.7927474975586, \t Validation Loss: 0.48860454332758807, \t Validation accuracy: 81.07965087890625\n",
      "Starting epoch 12\n",
      "Epoch 12 \t\t Training Loss: 0.7934402890391368 \t \t Accuracy = 79.06330871582031, \t Validation Loss: 0.4897842578023498, \t Validation accuracy: 80.0281982421875\n",
      "Starting epoch 13\n",
      "Epoch 13 \t\t Training Loss: 0.7786270829715899 \t \t Accuracy = 83.38179779052734, \t Validation Loss: 0.4736485171039202, \t Validation accuracy: 85.39708709716797\n",
      "Validation Loss Decreased(0.474834--->0.473649) \t Saving The Model\n",
      "Starting epoch 14\n",
      "Epoch 14 \t\t Training Loss: 0.7675128015304419 \t \t Accuracy = 85.89314270019531, \t Validation Loss: 0.47177702676483063, \t Validation accuracy: 86.13722229003906\n",
      "Validation Loss Decreased(0.473649--->0.471777) \t Saving The Model\n",
      "Starting epoch 15\n",
      "Epoch 15 \t\t Training Loss: 0.7622883122666437 \t \t Accuracy = 86.24120330810547, \t Validation Loss: 0.47245149619398064, \t Validation accuracy: 86.0726089477539\n",
      "Starting epoch 16\n",
      "Epoch 16 \t\t Training Loss: 0.7582326868086829 \t \t Accuracy = 86.32051086425781, \t Validation Loss: 0.47204481230841744, \t Validation accuracy: 86.47203826904297\n",
      "Starting epoch 17\n",
      "Epoch 17 \t\t Training Loss: 0.7545029174088311 \t \t Accuracy = 86.41890716552734, \t Validation Loss: 0.4728409919822425, \t Validation accuracy: 86.40155029296875\n",
      "Starting epoch 18\n",
      "Epoch 18 \t\t Training Loss: 0.7512160167938337 \t \t Accuracy = 86.50996398925781, \t Validation Loss: 0.47216664280807763, \t Validation accuracy: 86.36043548583984\n",
      "Starting epoch 19\n",
      "Epoch 19 \t\t Training Loss: 0.7488209224845234 \t \t Accuracy = 86.3865966796875, \t Validation Loss: 0.4734145010772504, \t Validation accuracy: 86.04911041259766\n",
      "Starting epoch 20\n",
      "Epoch 20 \t\t Training Loss: 0.7509410756086945 \t \t Accuracy = 85.00389099121094, \t Validation Loss: 0.47522282687544126, \t Validation accuracy: 85.48519897460938\n",
      "Starting epoch 21\n",
      "Epoch 21 \t\t Training Loss: 0.747786739336929 \t \t Accuracy = 86.07598876953125, \t Validation Loss: 0.47348005816950434, \t Validation accuracy: 86.13722229003906\n",
      "Starting epoch 22\n",
      "Epoch 22 \t\t Training Loss: 0.7454995980024114 \t \t Accuracy = 86.34327697753906, \t Validation Loss: 0.47398707427476583, \t Validation accuracy: 85.9375\n",
      "Starting epoch 23\n",
      "Epoch 23 \t\t Training Loss: 0.7442160415554181 \t \t Accuracy = 86.12445068359375, \t Validation Loss: 0.4735756762195052, \t Validation accuracy: 86.20771026611328\n",
      "Starting epoch 24\n",
      "Epoch 24 \t\t Training Loss: 0.740342663306939 \t \t Accuracy = 86.1956787109375, \t Validation Loss: 0.4725431930600551, \t Validation accuracy: 86.41329956054688\n",
      "Starting epoch 25\n",
      "Epoch 25 \t\t Training Loss: 0.7358791424535719 \t \t Accuracy = 86.44020080566406, \t Validation Loss: 0.47262553635396454, \t Validation accuracy: 86.41329956054688\n",
      "Starting epoch 26\n",
      "Epoch 26 \t\t Training Loss: 0.7330272622350463 \t \t Accuracy = 86.34915161132812, \t Validation Loss: 0.47430901325236985, \t Validation accuracy: 85.7319107055664\n",
      "Starting epoch 27\n",
      "Epoch 27 \t\t Training Loss: 0.7311082397468556 \t \t Accuracy = 86.02972412109375, \t Validation Loss: 0.4735392058453365, \t Validation accuracy: 85.99624633789062\n",
      "Starting epoch 28\n",
      "Epoch 28 \t\t Training Loss: 0.7273859783895034 \t \t Accuracy = 86.32711791992188, \t Validation Loss: 0.47245227924564426, \t Validation accuracy: 86.44267272949219\n",
      "Starting epoch 29\n",
      "Epoch 29 \t\t Training Loss: 0.7234087411482307 \t \t Accuracy = 86.3851318359375, \t Validation Loss: 0.4732774562305874, \t Validation accuracy: 86.33106231689453\n",
      "Starting epoch 30\n",
      "Epoch 30 \t\t Training Loss: 0.7233202264301086 \t \t Accuracy = 85.72645568847656, \t Validation Loss: 0.4752365688831485, \t Validation accuracy: 85.73778533935547\n",
      "Starting epoch 31\n",
      "Epoch 31 \t\t Training Loss: 0.721444248789011 \t \t Accuracy = 86.05762481689453, \t Validation Loss: 0.47532025415297835, \t Validation accuracy: 85.80827331542969\n",
      "Starting epoch 32\n",
      "Epoch 32 \t\t Training Loss: 0.7190997413590663 \t \t Accuracy = 86.3388671875, \t Validation Loss: 0.47245130866591695, \t Validation accuracy: 86.3839340209961\n",
      "Starting epoch 33\n",
      "Epoch 33 \t\t Training Loss: 0.7192960749975497 \t \t Accuracy = 85.7778549194336, \t Validation Loss: 0.4749175024311445, \t Validation accuracy: 85.86701202392578\n",
      "Starting epoch 34\n",
      "Epoch 34 \t\t Training Loss: 0.718338452069495 \t \t Accuracy = 85.95188903808594, \t Validation Loss: 0.47304120973536845, \t Validation accuracy: 86.39567565917969\n",
      "Starting epoch 35\n",
      "Epoch 35 \t\t Training Loss: 0.7170907052695975 \t \t Accuracy = 86.06497192382812, \t Validation Loss: 0.4752639253237094, \t Validation accuracy: 85.61442565917969\n",
      "Starting epoch 36\n",
      "Epoch 36 \t\t Training Loss: 0.7192215432125822 \t \t Accuracy = 85.43199157714844, \t Validation Loss: 0.47350076973786825, \t Validation accuracy: 86.44267272949219\n",
      "Starting epoch 37\n",
      "Epoch 37 \t\t Training Loss: 0.7162818703660392 \t \t Accuracy = 86.40495300292969, \t Validation Loss: 0.47337759551946185, \t Validation accuracy: 86.40742492675781\n",
      "Starting epoch 38\n",
      "Epoch 38 \t\t Training Loss: 0.716440058852497 \t \t Accuracy = 86.21770477294922, \t Validation Loss: 0.4753504074804964, \t Validation accuracy: 85.6026840209961\n",
      "Starting epoch 39\n",
      "Epoch 39 \t\t Training Loss: 0.715448189274709 \t \t Accuracy = 86.2911376953125, \t Validation Loss: 0.47316776468739874, \t Validation accuracy: 86.67176055908203\n",
      "Starting epoch 40\n",
      "Epoch 40 \t\t Training Loss: 0.7125221501503672 \t \t Accuracy = 86.5848617553711, \t Validation Loss: 0.4725553273108968, \t Validation accuracy: 86.34868621826172\n",
      "Starting epoch 41\n",
      "Epoch 41 \t\t Training Loss: 0.7090495795543704 \t \t Accuracy = 86.33226013183594, \t Validation Loss: 0.47353145149019027, \t Validation accuracy: 85.86701202392578\n",
      "Starting epoch 42\n",
      "Epoch 42 \t\t Training Loss: 0.7140297351082913 \t \t Accuracy = 84.89741516113281, \t Validation Loss: 0.4745216655452349, \t Validation accuracy: 86.0843505859375\n",
      "Starting epoch 43\n",
      "Epoch 43 \t\t Training Loss: 0.711165690346432 \t \t Accuracy = 85.75582885742188, \t Validation Loss: 0.4755839147762945, \t Validation accuracy: 85.45582580566406\n",
      "Starting epoch 44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 \t\t Training Loss: 0.7124645276821422 \t \t Accuracy = 85.47972106933594, \t Validation Loss: 0.47426410045540124, \t Validation accuracy: 86.20183563232422\n",
      "Starting epoch 45\n",
      "Epoch 45 \t\t Training Loss: 0.7118819086651381 \t \t Accuracy = 85.578125, \t Validation Loss: 0.4746661520840829, \t Validation accuracy: 86.00211334228516\n",
      "Starting epoch 46\n",
      "Epoch 46 \t\t Training Loss: 0.7109522911811009 \t \t Accuracy = 85.8255844116211, \t Validation Loss: 0.4749794551852154, \t Validation accuracy: 85.90225982666016\n",
      "Starting epoch 47\n",
      "Epoch 47 \t\t Training Loss: 0.7095366735151387 \t \t Accuracy = 86.2984848022461, \t Validation Loss: 0.473384239868811, \t Validation accuracy: 86.50141143798828\n",
      "Starting epoch 48\n",
      "Epoch 48 \t\t Training Loss: 0.7092230151078307 \t \t Accuracy = 86.21990966796875, \t Validation Loss: 0.4737964148758448, \t Validation accuracy: 86.56015014648438\n",
      "Starting epoch 49\n",
      "Epoch 49 \t\t Training Loss: 0.7086130321670071 \t \t Accuracy = 86.05762481689453, \t Validation Loss: 0.47453308192610044, \t Validation accuracy: 86.14309692382812\n",
      "Starting epoch 50\n",
      "Epoch 50 \t\t Training Loss: 0.7064660450065494 \t \t Accuracy = 86.27938842773438, \t Validation Loss: 0.4737428768336424, \t Validation accuracy: 86.54840087890625\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "#loss_function = nn.functional.binary_cross_entropy\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_fusion2.parameters(), lr=2.5e-5)\n",
    "batch_size=32\n",
    "n_batches=np.ceil(len(ecg_train)/batch_size).astype(np.int64)\n",
    "valid_batch_size=100\n",
    "valid_batches=np.ceil(len(ecg_valid)/valid_batch_size).astype(np.int64) \n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(0, 50): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    current_tot_loss=0.0\n",
    "    correct=0\n",
    "    i=0\n",
    "    # Iterate over the DataLoader for training data\n",
    "    ind_list = list(range(len(ecg_train)))\n",
    "    shuffle(ind_list)\n",
    "    #train_new  = train[ind_list, :,:,:]\n",
    "    #target_new = target[ind_list,]\n",
    "    while i<n_batches:\n",
    "\n",
    "          # Get inputs\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_wide[i*batch_size:(i+1)*batch_size,]\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_num[i*batch_size:(i+1)*batch_size,]\n",
    "        local_ecg, local_y, local_ppg, local_ecg_sqi,local_ppg_sqi = ecg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),y_train_num[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ppg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ecg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),ppg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda()\n",
    "        #if torch.cuda.is_available():\n",
    "        #    local_X, local_y = local_X.cuda(), local_y.cuda()\n",
    "\n",
    "          # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs_c, outputs_ecg, outputs_ppg = model_fusion2(local_ecg.float(),local_ppg.float(),local_ecg_sqi.float(), local_ppg_sqi.float())\n",
    "        \n",
    "        \n",
    "\n",
    "        # Compute loss\n",
    "        loss1 = loss_function(outputs_c, local_y)\n",
    "        loss2 = loss_function(outputs_ecg, local_y)\n",
    "        loss3 = loss_function(outputs_ppg, local_y)\n",
    "        loss=(loss1+loss2+loss3)/3\n",
    "        #loss=loss1\n",
    "        #print(loss)\n",
    "        \n",
    "        #loss = loss_function(outputs, local_y.float())\n",
    "        l2_lambda = 0.01\n",
    "        l2_reg = torch.tensor(0.).cuda()\n",
    "        for param in model_fusion2.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += l2_lambda * l2_reg\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        output = outputs_c.clone()\n",
    "        output= torch.argmax(output, axis=1)\n",
    "        \n",
    "        correct += (output == local_y).float().sum()\n",
    "\n",
    "        # Print statistics\n",
    "        \n",
    "        #current_loss += loss.item()\n",
    "        current_tot_loss+=loss.item()\n",
    "       # if i % 20 == 19:\n",
    "       #     print('Loss after mini-batch %5d: %.3f' %\n",
    "       #         (i + 1, current_loss / 20))\n",
    "       #     current_loss = 0.0\n",
    "        i=i+1\n",
    "        \n",
    "    \n",
    "    \n",
    "    correct_valid=0\n",
    "    current_valid_loss = 0.0\n",
    "    current_valid_tot_loss=0.0\n",
    "    j=0\n",
    "    while j<valid_batches:\n",
    "        model_fusion2.eval()     # Optional when not using Model Specific layer\n",
    "        local_ecg_valid, local_y_valid, local_ppg_valid, local_ecg_sqi_valid,local_ppg_sqi_valid = ecg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),y_valid_num[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ppg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ecg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),ppg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda()\n",
    "        target, target2, target3 = model_fusion2(local_ecg_valid.float(),local_ppg_valid.float(),local_ecg_sqi_valid.float(), local_ppg_sqi_valid.float())\n",
    "        loss1 = loss_function(target,local_y_valid)\n",
    "        loss2 = loss_function(target2,local_y_valid)\n",
    "        loss3 = loss_function(target3,local_y_valid)\n",
    "        #loss=loss1\n",
    "        loss=(loss1+loss2+loss3)/3\n",
    "        current_valid_loss+=loss.item()\n",
    "        #valid_loss = loss.item() \n",
    "        target= torch.argmax(target, axis=1)\n",
    "        correct_valid += (target == local_y_valid).float().sum()\n",
    "        j=j+1\n",
    "    \n",
    "    #print(correct)\n",
    "    #print(current_tot_loss)\n",
    "    accuracy = 100 * correct / len(ecg_train)\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {current_tot_loss / n_batches} \\t \\t Accuracy = {accuracy}, \\t Validation Loss: {current_valid_loss/ valid_batches}, \\t Validation accuracy: {100*correct_valid/len(ecg_valid)}')\n",
    "    \n",
    "    if min_valid_loss > (current_valid_loss/valid_batches):\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{current_valid_loss/valid_batches:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = (current_valid_loss/valid_batches)\n",
    "        # Saving State Dict\n",
    "        torch.save(model_fusion2.state_dict(), 'saved_model_fusion_noise_0.01_avg_loss_-20.pth')\n",
    "        \n",
    "        \n",
    "    \n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9274d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = fusion_model_v3()\n",
    "model_saved.load_state_dict(torch.load('saved_model_fusion_noise_0.01_avg_loss_-20.pth'))\n",
    "model_saved.eval()\n",
    "model_saved=model_saved.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eccd02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8894)\n",
      "[[7273 1238]\n",
      " [ 306 5142]]\n"
     ]
    }
   ],
   "source": [
    "outputs_test,out1,out2 = model_saved(ecg_test.float(), ppg_test.float(), ecg_sqi_test.float(), ppg_sqi_test.float())\n",
    "outputs_test = outputs_test.clone()\n",
    "outputs_test= torch.argmax(outputs_test, axis=1)\n",
    "        \n",
    "correct = (outputs_test == y_test_num).float().sum()\n",
    "print(correct/len(ecg_test))\n",
    "\n",
    "cm=confusion_matrix(y_test_num.cpu(), outputs_test.cpu())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10e45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
