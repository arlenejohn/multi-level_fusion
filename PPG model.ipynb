{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679be018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mat4py import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from scipy import signal\n",
    "import os\n",
    "from scipy.linalg import circulant\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3fa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20c37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('D:\\PhD topics\\Datasets\\Afib_datasets\\store_no_noise_one_mean_final.pkl', 'rb')\n",
    "#file= open('store_no_noise.pkl','rb')\n",
    "obj = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20945cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ecg_train': array([[ 0.08608023,  0.08581871,  0.08469403, ...,  0.05728371,\n",
       "          0.05974232,  0.06223159],\n",
       "        [ 0.06668394,  0.06740808,  0.06773192, ...,  0.07126522,\n",
       "          0.07099152,  0.07027662],\n",
       "        [ 0.07094166,  0.07212875,  0.07197245, ...,  0.06147816,\n",
       "          0.06396077,  0.06554425],\n",
       "        ...,\n",
       "        [-0.15816909, -0.17019585, -0.10206373, ..., -0.03658568,\n",
       "         -0.04920873, -0.10357655],\n",
       "        [-0.03617069, -0.02199404,  0.00623482, ..., -0.04964932,\n",
       "         -0.03607034, -0.03592465],\n",
       "        [-0.1316477 , -0.10271109, -0.11659159, ...,  0.01697524,\n",
       "          0.07166445,  0.15376595]]),\n",
       " 'ppg_train': array([[ 0.06185318,  0.06131563,  0.06131563, ...,  0.06239073,\n",
       "          0.06239073,  0.06239073],\n",
       "        [ 0.05970299,  0.05970299,  0.05970299, ...,  0.06024053,\n",
       "          0.06024053,  0.05970299],\n",
       "        [ 0.05378996,  0.05378996,  0.05325241, ...,  0.06077808,\n",
       "          0.06131563,  0.06131563],\n",
       "        ...,\n",
       "        [ 0.79320376,  0.73671454,  0.67215543, ..., -0.53686063,\n",
       "         -0.49577756, -0.43195208],\n",
       "        [-0.1949908 , -0.19792531, -0.1920563 , ...,  0.62080159,\n",
       "          0.57531676,  0.52763105],\n",
       "        [ 0.29580516,  0.34422449,  0.39337745, ..., -0.26028354,\n",
       "         -0.25001277, -0.24561101]]),\n",
       " 'ecg_valid': array([[ 0.05958773,  0.0612712 ,  0.06207788, ...,  0.06660471,\n",
       "          0.06817922,  0.06933014],\n",
       "        [ 0.06384546,  0.06315947,  0.06113554, ...,  0.05728371,\n",
       "          0.05833616,  0.0584457 ],\n",
       "        [ 0.04776072,  0.04805331,  0.04888513, ...,  0.06147816,\n",
       "          0.06396077,  0.06601749],\n",
       "        ...,\n",
       "        [-0.2536461 , -0.29325628, -0.23809728, ..., -0.22339572,\n",
       "         -0.11752835, -0.07704639],\n",
       "        [-0.02290999, -0.00876173,  0.01944196, ..., -0.06401932,\n",
       "         -0.04920873, -0.07704639],\n",
       "        [ 0.03145886,  0.0057938 ,  0.0326491 , ...,  0.07053616,\n",
       "          0.03093545,  0.11397072]]),\n",
       " 'ppg_valid': array([[ 0.05325241,  0.05271486,  0.05271486, ...,  0.05970299,\n",
       "          0.06077808,  0.06239073],\n",
       "        [ 0.05701524,  0.0564777 ,  0.05594015, ...,  0.04948957,\n",
       "          0.04948957,  0.04948957],\n",
       "        [ 0.04465164,  0.04411409,  0.04303899, ...,  0.0398137 ,\n",
       "          0.0398137 ,  0.0398137 ],\n",
       "        ...,\n",
       "        [ 0.83795496,  0.81888068,  0.7917365 , ..., -0.25881628,\n",
       "         -0.25588178, -0.27275518],\n",
       "        [-0.01451874,  0.02142894,  0.0397696 , ..., -0.39160264,\n",
       "         -0.28742771, -0.16197762],\n",
       "        [-0.37766374, -0.37693011, -0.38206549, ...,  0.26205835,\n",
       "          0.19456474,  0.12193574]]),\n",
       " 'ecg_test': array([[ 0.0628993 ,  0.06646394,  0.06773192, ...,  0.07033311,\n",
       "          0.07146024,  0.07216956],\n",
       "        [ 0.06904934,  0.06929635,  0.0696166 , ...,  0.06567261,\n",
       "          0.06677307,  0.06791043],\n",
       "        [ 0.07661863,  0.07920977,  0.08092468, ...,  0.06427446,\n",
       "          0.0648982 ,  0.06649072],\n",
       "        ...,\n",
       "        [ 0.09908841,  0.08651086,  0.12774052, ..., -0.03658568,\n",
       "         -0.06366096, -0.03592465],\n",
       "        [-0.15816909, -0.15696354, -0.21036229, ...,  0.07053616,\n",
       "          0.08480284,  0.04499232],\n",
       "        [-0.10380024, -0.11726663, -0.04791446, ..., -0.04964932,\n",
       "         -0.07679935, -0.04918973]]),\n",
       " 'ppg_test': array([[ 0.05755279,  0.05701524,  0.05701524, ...,  0.06077808,\n",
       "          0.06077808,  0.06077808],\n",
       "        [ 0.05594015,  0.05594015,  0.0554026 , ...,  0.05970299,\n",
       "          0.05970299,  0.05970299],\n",
       "        [ 0.05594015,  0.05594015,  0.05594015, ...,  0.06077808,\n",
       "          0.06077808,  0.06077808],\n",
       "        ...,\n",
       "        [-0.27862419, -0.2984321 , -0.31457188, ..., -0.80169971,\n",
       "         -0.80463421, -0.81050322],\n",
       "        [ 0.04563861,  0.13440739,  0.22757792, ..., -0.6058215 ,\n",
       "         -0.62122765, -0.63590018],\n",
       "        [-1.35852203, -1.35852203, -1.35852203, ...,  0.28700165,\n",
       "          0.32808472,  0.37356954]]),\n",
       " 'y_train': array([1., 1., 1., ..., 0., 0., 0.]),\n",
       " 'y_valid': array([1., 1., 1., ..., 0., 0., 0.]),\n",
       " 'y_test': array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'ecg_sqi_train': array([[1.1018356 , 1.1018356 , 1.10183414, ..., 1.10333004, 1.09851604,\n",
       "         1.09636688],\n",
       "        [1.10089105, 1.10089105, 1.10088825, ..., 1.08230216, 1.08166779,\n",
       "         1.08093982],\n",
       "        [1.10617243, 1.10617243, 1.10616   , ..., 1.10211698, 1.10209136,\n",
       "         1.1020873 ],\n",
       "        ...,\n",
       "        [1.1509809 , 1.1509809 , 1.15080057, ..., 1.14206165, 1.14140238,\n",
       "         1.13993708],\n",
       "        [1.57923653, 1.57923653, 1.57874035, ..., 1.70681259, 1.70467748,\n",
       "         1.704421  ],\n",
       "        [1.15943091, 1.15943091, 1.15919514, ..., 1.16213952, 1.16168196,\n",
       "         1.16105309]]),\n",
       " 'ppg_sqi_train': array([[1.26787661, 1.26754924, 1.26721632, ..., 1.26600825, 1.26627875,\n",
       "         1.26653956],\n",
       "        [1.26619934, 1.26615388, 1.26610694, ..., 1.26586098, 1.26606712,\n",
       "         1.26617294],\n",
       "        [1.26735642, 1.26918249, 1.2705165 , ..., 1.26549997, 1.26582383,\n",
       "         1.26582202],\n",
       "        ...,\n",
       "        [2.33332539, 2.33332539, 2.33434344, ..., 1.33710327, 1.33739421,\n",
       "         1.33791083],\n",
       "        [1.71714045, 1.71714045, 1.77719597, ..., 2.68386914, 2.68462641,\n",
       "         2.68523879],\n",
       "        [2.63256402, 2.63256402, 2.63092169, ..., 2.4438455 , 2.29585293,\n",
       "         2.29606476]]),\n",
       " 'ecg_sqi_valid': array([[1.10106001, 1.10499074, 1.10511649, ..., 1.08376888, 1.08357314,\n",
       "         1.08364141],\n",
       "        [1.089887  , 1.09487797, 1.09467863, ..., 1.10307633, 1.10331103,\n",
       "         1.10331478],\n",
       "        [1.09878278, 1.09878278, 1.09882656, ..., 1.09988725, 1.08485163,\n",
       "         1.08567348],\n",
       "        ...,\n",
       "        [1.13862979, 1.13862979, 1.13901431, ..., 1.39033925, 1.40213375,\n",
       "         1.40265229],\n",
       "        [1.7173198 , 1.7173198 , 1.71831876, ..., 1.15189086, 1.15181704,\n",
       "         1.15197252],\n",
       "        [1.56246854, 1.53536639, 1.53448975, ..., 1.61203918, 1.61204481,\n",
       "         1.61215116]]),\n",
       " 'ppg_sqi_valid': array([[1.26689861, 1.26669268, 1.26647788, ..., 1.2673134 , 1.26713105,\n",
       "         1.26713105],\n",
       "        [1.26585763, 1.26589229, 1.26593178, ..., 1.26598244, 1.26608196,\n",
       "         1.26608196],\n",
       "        [1.26546768, 1.26548764, 1.2654812 , ..., 1.27007665, 1.27088046,\n",
       "         1.27088046],\n",
       "        ...,\n",
       "        [3.18802309, 3.18802309, 3.18869605, ..., 1.16984106, 1.16847536,\n",
       "         1.16737093],\n",
       "        [2.28457313, 2.28457313, 2.27520591, ..., 1.35401548, 1.35444884,\n",
       "         1.35479948],\n",
       "        [1.06386867, 1.06386867, 1.06367439, ..., 1.25073372, 1.2578942 ,\n",
       "         1.26267448]]),\n",
       " 'ecg_sqi_test': array([[1.10013283, 1.10013283, 1.10020435, ..., 1.10002386, 1.09995183,\n",
       "         1.09989031],\n",
       "        [1.10168297, 1.10168297, 1.10166255, ..., 1.10354517, 1.10357919,\n",
       "         1.10361254],\n",
       "        [1.0997491 , 1.0997491 , 1.10036771, ..., 1.10274794, 1.10275512,\n",
       "         1.10276759],\n",
       "        ...,\n",
       "        [1.11177999, 1.11177999, 1.11200515, ..., 1.84604399, 1.8294966 ,\n",
       "         1.76012256],\n",
       "        [1.68072205, 1.68072205, 1.68042126, ..., 1.81740877, 1.71533356,\n",
       "         1.43960775],\n",
       "        [1.12631994, 1.12631994, 1.12662507, ..., 1.12073171, 1.12056879,\n",
       "         1.1204128 ]]),\n",
       " 'ppg_sqi_test': array([[1.26787407, 1.26787407, 1.26753681, ..., 1.26517698, 1.26549062,\n",
       "         1.26580908],\n",
       "        [1.26718131, 1.26697123, 1.26674243, ..., 1.26639454, 1.26634401,\n",
       "         1.26629311],\n",
       "        [1.26637129, 1.26635225, 1.26635225, ..., 1.26592132, 1.26606355,\n",
       "         1.2662037 ],\n",
       "        ...,\n",
       "        [1.29967066, 1.29967066, 1.29628264, ..., 2.86764376, 2.89413997,\n",
       "         2.9142247 ],\n",
       "        [2.30145201, 2.30145201, 2.30236459, ..., 2.65801236, 2.43200971,\n",
       "         2.44151733],\n",
       "        [1.26610839, 1.26610839, 1.26610839, ..., 1.48444693, 1.49290216,\n",
       "         1.4991444 ]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402789ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_train=obj['ppg_train']\n",
    "ppg_valid=obj['ppg_valid']\n",
    "ppg_test=obj['ppg_test']\n",
    "y_train=obj['y_train']\n",
    "y_valid=obj['y_valid']\n",
    "y_test=obj['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effb384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_sqi_train=obj['ppg_sqi_train']\n",
    "ppg_sqi_valid=obj['ppg_sqi_valid']\n",
    "ppg_sqi_test=obj['ppg_sqi_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c85ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cda8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06185318,  0.06131563,  0.06131563, ...,  0.06239073,\n",
       "         0.06239073,  0.06239073],\n",
       "       [ 0.05970299,  0.05970299,  0.05970299, ...,  0.06024053,\n",
       "         0.06024053,  0.05970299],\n",
       "       [ 0.05378996,  0.05378996,  0.05325241, ...,  0.06077808,\n",
       "         0.06131563,  0.06131563],\n",
       "       ...,\n",
       "       [ 0.79320376,  0.73671454,  0.67215543, ..., -0.53686063,\n",
       "        -0.49577756, -0.43195208],\n",
       "       [-0.1949908 , -0.19792531, -0.1920563 , ...,  0.62080159,\n",
       "         0.57531676,  0.52763105],\n",
       "       [ 0.29580516,  0.34422449,  0.39337745, ..., -0.26028354,\n",
       "        -0.25001277, -0.24561101]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf554fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_sqi_train_mean=np.mean(ppg_sqi_train, axis=0)\n",
    "ppg_sqi_train_std=np.std(ppg_sqi_train, axis=0)\n",
    "\n",
    "for i in range(ppg_sqi_train.shape[0]):\n",
    "    ppg_sqi_train[i,:]=(ppg_sqi_train[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n",
    "    \n",
    "for i in range(ppg_sqi_valid.shape[0]):\n",
    "    ppg_sqi_valid[i,:]=(ppg_sqi_valid[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n",
    "    \n",
    "for i in range(ppg_sqi_test.shape[0]):\n",
    "    ppg_sqi_test[i,:]=(ppg_sqi_test[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f85a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_train=np.expand_dims(ppg_train, axis=1)\n",
    "ppg_valid=np.expand_dims(ppg_valid, axis=1)\n",
    "\n",
    "ppg_sqi_train=np.expand_dims(ppg_sqi_train, axis=1)\n",
    "ppg_sqi_valid=np.expand_dims(ppg_sqi_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d436ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_test=np.expand_dims(ppg_test, axis=1)\n",
    "\n",
    "ppg_sqi_test=np.expand_dims(ppg_sqi_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886d29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d141a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_train_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_train_num = y_train_encoder.fit_transform(y_train)\n",
    "y_train_wide = to_categorical(y_train_num, num_classes)\n",
    "\n",
    "y_valid_num = y_train_encoder.fit_transform(y_valid)\n",
    "y_valid_wide = to_categorical(y_valid_num, num_classes)\n",
    "\n",
    "y_test_num = y_train_encoder.fit_transform(y_test)\n",
    "y_test_wide = to_categorical(y_test_num, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f99e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_train = torch.from_numpy(ppg_train)\n",
    "ppg_valid=torch.from_numpy(ppg_valid)\n",
    "ppg_test = torch.from_numpy(ppg_test)\n",
    "\n",
    "ppg_sqi_train = torch.from_numpy(ppg_sqi_train)\n",
    "ppg_sqi_valid=torch.from_numpy(ppg_sqi_valid)\n",
    "ppg_sqi_test = torch.from_numpy(ppg_sqi_test)\n",
    "\n",
    "y_train_wide = torch.from_numpy(y_train_wide)\n",
    "y_valid_wide = torch.from_numpy(y_valid_wide)\n",
    "y_test_wide = torch.from_numpy(y_test_wide)\n",
    "y_train_num = torch.from_numpy(y_train_num)\n",
    "y_valid_num = torch.from_numpy(y_valid_num)\n",
    "y_test_num = torch.from_numpy(y_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b6fe1a",
   "metadata": {},
   "source": [
    "## PPG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6342315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ppg_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.bn1_ppg=nn.BatchNorm1d(1)\n",
    "        self.conv1_ppg = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ppg = nn.LeakyReLU()\n",
    "        self.max1_ppg = nn.MaxPool1d(2)\n",
    "        self.drop1_ppg=nn.Dropout(0.25)\n",
    "        self.conv2_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ppg = nn.MaxPool1d(2)\n",
    "        self.relu2_ppg = nn.LeakyReLU()\n",
    "        self.drop2_ppg=nn.Dropout(0.25)\n",
    "        self.conv3_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ppg=nn.Dropout(0.25)\n",
    "        self.conv4_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ppg = nn.MaxPool1d(2)\n",
    "        self.relu4_ppg = nn.LeakyReLU()\n",
    "        self.bn2_ppg=nn.BatchNorm1d(5)\n",
    "        self.flat_ppg=nn.Flatten()\n",
    "        self.drop4_ppg=nn.Dropout(0.25)\n",
    "        self.linear1_ppg=nn.Linear(660,2)\n",
    "        self.softm_ppg=nn.Softmax()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def forward(self, ppg):\n",
    "        \n",
    "       \n",
    "        out_ppg_bn1=self.bn1_ppg(ppg)\n",
    "        out_ppg_conv1= self.conv1_ppg(out_ppg_bn1)\n",
    "        out_ppg_relu1 = self.relu1_ppg(out_ppg_conv1)\n",
    "        out_ppg_max1=self.max1_ppg(out_ppg_relu1)\n",
    "        out_ppg_drop1=self.drop1_ppg(out_ppg_max1)\n",
    "        out_ppg_conv2=self.conv2_ppg(out_ppg_drop1)\n",
    "        out_ppg_max2=self.max2_ppg(out_ppg_conv2)\n",
    "        out_ppg_relu2=self.relu2_ppg(out_ppg_max2)\n",
    "        out_ppg_drop2=self.drop2_ppg(out_ppg_relu2)\n",
    "        out_ppg_conv3=self.conv3_ppg(out_ppg_drop2)\n",
    "        out_ppg_drop3=self.drop3_ppg(out_ppg_conv3)\n",
    "        out_ppg_conv4=self.conv4_ppg(out_ppg_drop3)\n",
    "        out_ppg_max4=self.max4_ppg(out_ppg_conv4)\n",
    "        out_ppg_relu4=self.relu4_ppg(out_ppg_max4)\n",
    "        out_ppg_bn2=self.bn2_ppg(out_ppg_relu4)\n",
    "        out_ppg_flat=self.flat_ppg(out_ppg_bn2)\n",
    "        out_ppg_drop4=self.drop4_ppg(out_ppg_flat)\n",
    "        out_ppg_linear=self.linear1_ppg(out_ppg_drop4)\n",
    "        out_ppg_softm=self.softm_ppg(out_ppg_linear)\n",
    "        \n",
    "\n",
    "\n",
    "        return out_ppg_softm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e2787df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ppg=ppg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db0689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_ppg = model_ppg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c55777f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.6514087572371713 \t \t Accuracy = 75.78460693359375, \t Validation Loss: 0.5799104850194607, \t Validation accuracy: 71.11724853515625\n",
      "Validation Loss Decreased(inf--->0.579910) \t Saving The Model\n",
      "Starting epoch 2\n",
      "Epoch 2 \t\t Training Loss: 0.5734046838225278 \t \t Accuracy = 84.70208740234375, \t Validation Loss: 0.46896425830690486, \t Validation accuracy: 84.83905029296875\n",
      "Validation Loss Decreased(0.579910--->0.468964) \t Saving The Model\n",
      "Starting epoch 3\n",
      "Epoch 3 \t\t Training Loss: 0.5592253665908947 \t \t Accuracy = 84.92825317382812, \t Validation Loss: 0.465575939730594, \t Validation accuracy: 84.86842346191406\n",
      "Validation Loss Decreased(0.468964--->0.465576) \t Saving The Model\n",
      "Starting epoch 4\n",
      "Epoch 4 \t\t Training Loss: 0.5519083332396427 \t \t Accuracy = 85.08907318115234, \t Validation Loss: 0.45845567238958257, \t Validation accuracy: 85.68492126464844\n",
      "Validation Loss Decreased(0.465576--->0.458456) \t Saving The Model\n",
      "Starting epoch 5\n",
      "Epoch 5 \t\t Training Loss: 0.5398474557857428 \t \t Accuracy = 85.99227142333984, \t Validation Loss: 0.45354675950362666, \t Validation accuracy: 86.06085968017578\n",
      "Validation Loss Decreased(0.458456--->0.453547) \t Saving The Model\n",
      "Starting epoch 6\n",
      "Epoch 6 \t\t Training Loss: 0.5339489088190678 \t \t Accuracy = 86.17584991455078, \t Validation Loss: 0.4522777715621636, \t Validation accuracy: 86.19596099853516\n",
      "Validation Loss Decreased(0.453547--->0.452278) \t Saving The Model\n",
      "Starting epoch 7\n",
      "Epoch 7 \t\t Training Loss: 0.5293837447293607 \t \t Accuracy = 86.2918701171875, \t Validation Loss: 0.45133388164447763, \t Validation accuracy: 86.29582214355469\n",
      "Validation Loss Decreased(0.452278--->0.451334) \t Saving The Model\n",
      "Starting epoch 8\n",
      "Epoch 8 \t\t Training Loss: 0.5255135528435161 \t \t Accuracy = 86.41009521484375, \t Validation Loss: 0.4500128201573913, \t Validation accuracy: 86.43092346191406\n",
      "Validation Loss Decreased(0.451334--->0.450013) \t Saving The Model\n",
      "Starting epoch 9\n",
      "Epoch 9 \t\t Training Loss: 0.5223085665515155 \t \t Accuracy = 86.5283203125, \t Validation Loss: 0.449363411692848, \t Validation accuracy: 86.44267272949219\n",
      "Validation Loss Decreased(0.450013--->0.449363) \t Saving The Model\n",
      "Starting epoch 10\n",
      "Epoch 10 \t\t Training Loss: 0.5197932527127459 \t \t Accuracy = 86.5657730102539, \t Validation Loss: 0.44892668253497076, \t Validation accuracy: 86.47203826904297\n",
      "Validation Loss Decreased(0.449363--->0.448927) \t Saving The Model\n",
      "Starting epoch 11\n",
      "Epoch 11 \t\t Training Loss: 0.517580049224478 \t \t Accuracy = 86.6311264038086, \t Validation Loss: 0.4479569947859, \t Validation accuracy: 86.62476348876953\n",
      "Validation Loss Decreased(0.448927--->0.447957) \t Saving The Model\n",
      "Starting epoch 12\n",
      "Epoch 12 \t\t Training Loss: 0.515666352402895 \t \t Accuracy = 86.68252563476562, \t Validation Loss: 0.44732963219720717, \t Validation accuracy: 86.64826202392578\n",
      "Validation Loss Decreased(0.447957--->0.447330) \t Saving The Model\n",
      "Starting epoch 13\n",
      "Epoch 13 \t\t Training Loss: 0.5139703677224934 \t \t Accuracy = 86.73612976074219, \t Validation Loss: 0.4467185568391231, \t Validation accuracy: 86.73637390136719\n",
      "Validation Loss Decreased(0.447330--->0.446719) \t Saving The Model\n",
      "Starting epoch 14\n",
      "Epoch 14 \t\t Training Loss: 0.5126244466177615 \t \t Accuracy = 86.8125, \t Validation Loss: 0.44577963136092963, \t Validation accuracy: 86.8656005859375\n",
      "Validation Loss Decreased(0.446719--->0.445780) \t Saving The Model\n",
      "Starting epoch 15\n",
      "Epoch 15 \t\t Training Loss: 0.5115973014188441 \t \t Accuracy = 86.82939147949219, \t Validation Loss: 0.4457283828690735, \t Validation accuracy: 86.94783782958984\n",
      "Validation Loss Decreased(0.445780--->0.445728) \t Saving The Model\n",
      "Starting epoch 16\n",
      "Epoch 16 \t\t Training Loss: 0.5107004119195324 \t \t Accuracy = 86.86610412597656, \t Validation Loss: 0.4454731570001234, \t Validation accuracy: 86.89497375488281\n",
      "Validation Loss Decreased(0.445728--->0.445473) \t Saving The Model\n",
      "Starting epoch 17\n",
      "Epoch 17 \t\t Training Loss: 0.5099603855016088 \t \t Accuracy = 86.87418365478516, \t Validation Loss: 0.44515135588004573, \t Validation accuracy: 86.93609619140625\n",
      "Validation Loss Decreased(0.445473--->0.445151) \t Saving The Model\n",
      "Starting epoch 18\n",
      "Epoch 18 \t\t Training Loss: 0.5093401337770703 \t \t Accuracy = 86.90575408935547, \t Validation Loss: 0.4454398200525875, \t Validation accuracy: 87.03007507324219\n",
      "Starting epoch 19\n",
      "Epoch 19 \t\t Training Loss: 0.5087324550963546 \t \t Accuracy = 86.90428924560547, \t Validation Loss: 0.44646359692540083, \t Validation accuracy: 86.94783782958984\n",
      "Starting epoch 20\n",
      "Epoch 20 \t\t Training Loss: 0.5081402428686282 \t \t Accuracy = 86.92191314697266, \t Validation Loss: 0.44528695557549686, \t Validation accuracy: 86.99483489990234\n",
      "Starting epoch 21\n",
      "Epoch 21 \t\t Training Loss: 0.507594531619067 \t \t Accuracy = 86.93218994140625, \t Validation Loss: 0.44494832886589897, \t Validation accuracy: 87.01832580566406\n",
      "Validation Loss Decreased(0.445151--->0.444948) \t Saving The Model\n",
      "Starting epoch 22\n",
      "Epoch 22 \t\t Training Loss: 0.5070723928020973 \t \t Accuracy = 86.94026947021484, \t Validation Loss: 0.44478868340191086, \t Validation accuracy: 87.01245880126953\n",
      "Validation Loss Decreased(0.444948--->0.444789) \t Saving The Model\n",
      "Starting epoch 23\n",
      "Epoch 23 \t\t Training Loss: 0.5065960582639826 \t \t Accuracy = 86.9461441040039, \t Validation Loss: 0.4451147751849994, \t Validation accuracy: 86.99483489990234\n",
      "Starting epoch 24\n",
      "Epoch 24 \t\t Training Loss: 0.5061624279119691 \t \t Accuracy = 86.9454116821289, \t Validation Loss: 0.4446329957211924, \t Validation accuracy: 87.03007507324219\n",
      "Validation Loss Decreased(0.444789--->0.444633) \t Saving The Model\n",
      "Starting epoch 25\n",
      "Epoch 25 \t\t Training Loss: 0.5057427414896009 \t \t Accuracy = 86.95348358154297, \t Validation Loss: 0.444664690578193, \t Validation accuracy: 87.07119750976562\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "#loss_function = nn.functional.binary_cross_entropy\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ppg.parameters(), lr=1.5e-5)\n",
    "batch_size=32\n",
    "n_batches=np.ceil(len(ppg_train)/batch_size).astype(np.int64)\n",
    "valid_batch_size=100\n",
    "valid_batches=np.ceil(len(ppg_valid)/valid_batch_size).astype(np.int64) \n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(0, 25): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    current_tot_loss=0.0\n",
    "    correct=0\n",
    "    i=0\n",
    "    # Iterate over the DataLoader for training data\n",
    "    ind_list = list(range(len(ppg_train)))\n",
    "    shuffle(ind_list)\n",
    "    #train_new  = train[ind_list, :,:,:]\n",
    "    #target_new = target[ind_list,]\n",
    "    while i<n_batches:\n",
    "\n",
    "          # Get inputs\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_wide[i*batch_size:(i+1)*batch_size,]\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_num[i*batch_size:(i+1)*batch_size,]\n",
    "        local_ppg, local_y,  = ppg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),y_train_num[ind_list[i*batch_size:(i+1)*batch_size],].cuda()\n",
    "        #if torch.cuda.is_available():\n",
    "        #    local_X, local_y = local_X.cuda(), local_y.cuda()\n",
    "\n",
    "          # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs_ppg =model_ppg(local_ppg.float())\n",
    "        \n",
    "        \n",
    "\n",
    "        # Compute loss\n",
    "       \n",
    "        loss = loss_function(outputs_ppg, local_y)\n",
    "        \n",
    "        #loss=loss1\n",
    "        #print(loss)\n",
    "        \n",
    "        #loss = loss_function(outputs, local_y.float())\n",
    "        l2_lambda = 0.01\n",
    "        l2_reg = torch.tensor(0.).cuda()\n",
    "        for param in model_ppg.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += l2_lambda * l2_reg\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        output = outputs_ppg.clone()\n",
    "        output= torch.argmax(output, axis=1)\n",
    "        \n",
    "        correct += (output == local_y).float().sum()\n",
    "\n",
    "        # Print statistics\n",
    "        \n",
    "        #current_loss += loss.item()\n",
    "        current_tot_loss+=loss.item()\n",
    "       # if i % 20 == 19:\n",
    "       #     print('Loss after mini-batch %5d: %.3f' %\n",
    "       #         (i + 1, current_loss / 20))\n",
    "       #     current_loss = 0.0\n",
    "        i=i+1\n",
    "        \n",
    "    \n",
    "    \n",
    "    correct_valid=0\n",
    "    current_valid_loss = 0.0\n",
    "    current_valid_tot_loss=0.0\n",
    "    j=0\n",
    "    while j<valid_batches:\n",
    "        model_ppg.eval()     # Optional when not using Model Specific layer\n",
    "        local_ppg_valid, local_y_valid = ppg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),y_valid_num[j*valid_batch_size:(j+1)*valid_batch_size,].cuda()\n",
    "        target = model_ppg(local_ppg_valid.float())\n",
    "        loss1 = loss_function(target,local_y_valid)\n",
    "        \n",
    "        loss=loss1\n",
    "        \n",
    "        current_valid_loss+=loss.item()\n",
    "        #valid_loss = loss.item() \n",
    "        target= torch.argmax(target, axis=1)\n",
    "        correct_valid += (target == local_y_valid).float().sum()\n",
    "        j=j+1\n",
    "    \n",
    "    #print(correct)\n",
    "    #print(current_tot_loss)\n",
    "    accuracy = 100 * correct / len(ppg_train)\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {current_tot_loss / n_batches} \\t \\t Accuracy = {accuracy}, \\t Validation Loss: {current_valid_loss/ valid_batches}, \\t Validation accuracy: {100*correct_valid/len(ppg_valid)}')\n",
    "    \n",
    "    if min_valid_loss > (current_valid_loss/valid_batches):\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{current_valid_loss/valid_batches:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = (current_valid_loss/valid_batches)\n",
    "        # Saving State Dict\n",
    "        torch.save(model_ppg.state_dict(), 'saved_model_ppg_no_noise_0.01.pth')\n",
    "        \n",
    "    \n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f6fc227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = ppg_model()\n",
    "model_saved.load_state_dict(torch.load('saved_model_ppg_no_noise_0.01.pth'))\n",
    "model_saved.eval()\n",
    "model_saved=model_saved.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8da0240e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPG output\n",
      "tensor(0.8671)\n",
      "[[6705 1806]\n",
      " [  49 5399]]\n"
     ]
    }
   ],
   "source": [
    "outputs_test = model_saved(ppg_test.float())\n",
    "outputs_test = outputs_test.clone()\n",
    "outputs_test= torch.argmax(outputs_test, axis=1)\n",
    "\n",
    "print(\"PPG output\")\n",
    "        \n",
    "correct = (outputs_test == y_test_num).float().sum()\n",
    "print(correct/len(ppg_test))\n",
    "\n",
    "cm=confusion_matrix(y_test_num.cpu(), outputs_test.cpu())\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c601f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
