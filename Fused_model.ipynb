{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679be018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mat4py import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from scipy import signal\n",
    "import os\n",
    "from scipy.linalg import circulant\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sklearn\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3fa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f20c37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('D:\\PhD topics\\Datasets\\Afib_datasets\\store_no_noise_one_mean_final.pkl', 'rb')\n",
    "#file= open('store_no_noise.pkl','rb')\n",
    "obj = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20945cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ecg_train': array([[ 0.08608023,  0.08581871,  0.08469403, ...,  0.05728371,\n",
       "          0.05974232,  0.06223159],\n",
       "        [ 0.06668394,  0.06740808,  0.06773192, ...,  0.07126522,\n",
       "          0.07099152,  0.07027662],\n",
       "        [ 0.07094166,  0.07212875,  0.07197245, ...,  0.06147816,\n",
       "          0.06396077,  0.06554425],\n",
       "        ...,\n",
       "        [-0.15816909, -0.17019585, -0.10206373, ..., -0.03658568,\n",
       "         -0.04920873, -0.10357655],\n",
       "        [-0.03617069, -0.02199404,  0.00623482, ..., -0.04964932,\n",
       "         -0.03607034, -0.03592465],\n",
       "        [-0.1316477 , -0.10271109, -0.11659159, ...,  0.01697524,\n",
       "          0.07166445,  0.15376595]]),\n",
       " 'ppg_train': array([[ 0.06185318,  0.06131563,  0.06131563, ...,  0.06239073,\n",
       "          0.06239073,  0.06239073],\n",
       "        [ 0.05970299,  0.05970299,  0.05970299, ...,  0.06024053,\n",
       "          0.06024053,  0.05970299],\n",
       "        [ 0.05378996,  0.05378996,  0.05325241, ...,  0.06077808,\n",
       "          0.06131563,  0.06131563],\n",
       "        ...,\n",
       "        [ 0.79320376,  0.73671454,  0.67215543, ..., -0.53686063,\n",
       "         -0.49577756, -0.43195208],\n",
       "        [-0.1949908 , -0.19792531, -0.1920563 , ...,  0.62080159,\n",
       "          0.57531676,  0.52763105],\n",
       "        [ 0.29580516,  0.34422449,  0.39337745, ..., -0.26028354,\n",
       "         -0.25001277, -0.24561101]]),\n",
       " 'ecg_valid': array([[ 0.05958773,  0.0612712 ,  0.06207788, ...,  0.06660471,\n",
       "          0.06817922,  0.06933014],\n",
       "        [ 0.06384546,  0.06315947,  0.06113554, ...,  0.05728371,\n",
       "          0.05833616,  0.0584457 ],\n",
       "        [ 0.04776072,  0.04805331,  0.04888513, ...,  0.06147816,\n",
       "          0.06396077,  0.06601749],\n",
       "        ...,\n",
       "        [-0.2536461 , -0.29325628, -0.23809728, ..., -0.22339572,\n",
       "         -0.11752835, -0.07704639],\n",
       "        [-0.02290999, -0.00876173,  0.01944196, ..., -0.06401932,\n",
       "         -0.04920873, -0.07704639],\n",
       "        [ 0.03145886,  0.0057938 ,  0.0326491 , ...,  0.07053616,\n",
       "          0.03093545,  0.11397072]]),\n",
       " 'ppg_valid': array([[ 0.05325241,  0.05271486,  0.05271486, ...,  0.05970299,\n",
       "          0.06077808,  0.06239073],\n",
       "        [ 0.05701524,  0.0564777 ,  0.05594015, ...,  0.04948957,\n",
       "          0.04948957,  0.04948957],\n",
       "        [ 0.04465164,  0.04411409,  0.04303899, ...,  0.0398137 ,\n",
       "          0.0398137 ,  0.0398137 ],\n",
       "        ...,\n",
       "        [ 0.83795496,  0.81888068,  0.7917365 , ..., -0.25881628,\n",
       "         -0.25588178, -0.27275518],\n",
       "        [-0.01451874,  0.02142894,  0.0397696 , ..., -0.39160264,\n",
       "         -0.28742771, -0.16197762],\n",
       "        [-0.37766374, -0.37693011, -0.38206549, ...,  0.26205835,\n",
       "          0.19456474,  0.12193574]]),\n",
       " 'ecg_test': array([[ 0.0628993 ,  0.06646394,  0.06773192, ...,  0.07033311,\n",
       "          0.07146024,  0.07216956],\n",
       "        [ 0.06904934,  0.06929635,  0.0696166 , ...,  0.06567261,\n",
       "          0.06677307,  0.06791043],\n",
       "        [ 0.07661863,  0.07920977,  0.08092468, ...,  0.06427446,\n",
       "          0.0648982 ,  0.06649072],\n",
       "        ...,\n",
       "        [ 0.09908841,  0.08651086,  0.12774052, ..., -0.03658568,\n",
       "         -0.06366096, -0.03592465],\n",
       "        [-0.15816909, -0.15696354, -0.21036229, ...,  0.07053616,\n",
       "          0.08480284,  0.04499232],\n",
       "        [-0.10380024, -0.11726663, -0.04791446, ..., -0.04964932,\n",
       "         -0.07679935, -0.04918973]]),\n",
       " 'ppg_test': array([[ 0.05755279,  0.05701524,  0.05701524, ...,  0.06077808,\n",
       "          0.06077808,  0.06077808],\n",
       "        [ 0.05594015,  0.05594015,  0.0554026 , ...,  0.05970299,\n",
       "          0.05970299,  0.05970299],\n",
       "        [ 0.05594015,  0.05594015,  0.05594015, ...,  0.06077808,\n",
       "          0.06077808,  0.06077808],\n",
       "        ...,\n",
       "        [-0.27862419, -0.2984321 , -0.31457188, ..., -0.80169971,\n",
       "         -0.80463421, -0.81050322],\n",
       "        [ 0.04563861,  0.13440739,  0.22757792, ..., -0.6058215 ,\n",
       "         -0.62122765, -0.63590018],\n",
       "        [-1.35852203, -1.35852203, -1.35852203, ...,  0.28700165,\n",
       "          0.32808472,  0.37356954]]),\n",
       " 'y_train': array([1., 1., 1., ..., 0., 0., 0.]),\n",
       " 'y_valid': array([1., 1., 1., ..., 0., 0., 0.]),\n",
       " 'y_test': array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'ecg_sqi_train': array([[1.1018356 , 1.1018356 , 1.10183414, ..., 1.10333004, 1.09851604,\n",
       "         1.09636688],\n",
       "        [1.10089105, 1.10089105, 1.10088825, ..., 1.08230216, 1.08166779,\n",
       "         1.08093982],\n",
       "        [1.10617243, 1.10617243, 1.10616   , ..., 1.10211698, 1.10209136,\n",
       "         1.1020873 ],\n",
       "        ...,\n",
       "        [1.1509809 , 1.1509809 , 1.15080057, ..., 1.14206165, 1.14140238,\n",
       "         1.13993708],\n",
       "        [1.57923653, 1.57923653, 1.57874035, ..., 1.70681259, 1.70467748,\n",
       "         1.704421  ],\n",
       "        [1.15943091, 1.15943091, 1.15919514, ..., 1.16213952, 1.16168196,\n",
       "         1.16105309]]),\n",
       " 'ppg_sqi_train': array([[1.26787661, 1.26754924, 1.26721632, ..., 1.26600825, 1.26627875,\n",
       "         1.26653956],\n",
       "        [1.26619934, 1.26615388, 1.26610694, ..., 1.26586098, 1.26606712,\n",
       "         1.26617294],\n",
       "        [1.26735642, 1.26918249, 1.2705165 , ..., 1.26549997, 1.26582383,\n",
       "         1.26582202],\n",
       "        ...,\n",
       "        [2.33332539, 2.33332539, 2.33434344, ..., 1.33710327, 1.33739421,\n",
       "         1.33791083],\n",
       "        [1.71714045, 1.71714045, 1.77719597, ..., 2.68386914, 2.68462641,\n",
       "         2.68523879],\n",
       "        [2.63256402, 2.63256402, 2.63092169, ..., 2.4438455 , 2.29585293,\n",
       "         2.29606476]]),\n",
       " 'ecg_sqi_valid': array([[1.10106001, 1.10499074, 1.10511649, ..., 1.08376888, 1.08357314,\n",
       "         1.08364141],\n",
       "        [1.089887  , 1.09487797, 1.09467863, ..., 1.10307633, 1.10331103,\n",
       "         1.10331478],\n",
       "        [1.09878278, 1.09878278, 1.09882656, ..., 1.09988725, 1.08485163,\n",
       "         1.08567348],\n",
       "        ...,\n",
       "        [1.13862979, 1.13862979, 1.13901431, ..., 1.39033925, 1.40213375,\n",
       "         1.40265229],\n",
       "        [1.7173198 , 1.7173198 , 1.71831876, ..., 1.15189086, 1.15181704,\n",
       "         1.15197252],\n",
       "        [1.56246854, 1.53536639, 1.53448975, ..., 1.61203918, 1.61204481,\n",
       "         1.61215116]]),\n",
       " 'ppg_sqi_valid': array([[1.26689861, 1.26669268, 1.26647788, ..., 1.2673134 , 1.26713105,\n",
       "         1.26713105],\n",
       "        [1.26585763, 1.26589229, 1.26593178, ..., 1.26598244, 1.26608196,\n",
       "         1.26608196],\n",
       "        [1.26546768, 1.26548764, 1.2654812 , ..., 1.27007665, 1.27088046,\n",
       "         1.27088046],\n",
       "        ...,\n",
       "        [3.18802309, 3.18802309, 3.18869605, ..., 1.16984106, 1.16847536,\n",
       "         1.16737093],\n",
       "        [2.28457313, 2.28457313, 2.27520591, ..., 1.35401548, 1.35444884,\n",
       "         1.35479948],\n",
       "        [1.06386867, 1.06386867, 1.06367439, ..., 1.25073372, 1.2578942 ,\n",
       "         1.26267448]]),\n",
       " 'ecg_sqi_test': array([[1.10013283, 1.10013283, 1.10020435, ..., 1.10002386, 1.09995183,\n",
       "         1.09989031],\n",
       "        [1.10168297, 1.10168297, 1.10166255, ..., 1.10354517, 1.10357919,\n",
       "         1.10361254],\n",
       "        [1.0997491 , 1.0997491 , 1.10036771, ..., 1.10274794, 1.10275512,\n",
       "         1.10276759],\n",
       "        ...,\n",
       "        [1.11177999, 1.11177999, 1.11200515, ..., 1.84604399, 1.8294966 ,\n",
       "         1.76012256],\n",
       "        [1.68072205, 1.68072205, 1.68042126, ..., 1.81740877, 1.71533356,\n",
       "         1.43960775],\n",
       "        [1.12631994, 1.12631994, 1.12662507, ..., 1.12073171, 1.12056879,\n",
       "         1.1204128 ]]),\n",
       " 'ppg_sqi_test': array([[1.26787407, 1.26787407, 1.26753681, ..., 1.26517698, 1.26549062,\n",
       "         1.26580908],\n",
       "        [1.26718131, 1.26697123, 1.26674243, ..., 1.26639454, 1.26634401,\n",
       "         1.26629311],\n",
       "        [1.26637129, 1.26635225, 1.26635225, ..., 1.26592132, 1.26606355,\n",
       "         1.2662037 ],\n",
       "        ...,\n",
       "        [1.29967066, 1.29967066, 1.29628264, ..., 2.86764376, 2.89413997,\n",
       "         2.9142247 ],\n",
       "        [2.30145201, 2.30145201, 2.30236459, ..., 2.65801236, 2.43200971,\n",
       "         2.44151733],\n",
       "        [1.26610839, 1.26610839, 1.26610839, ..., 1.48444693, 1.49290216,\n",
       "         1.4991444 ]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402789ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train=obj['ecg_train']\n",
    "ecg_valid=obj['ecg_valid']\n",
    "ecg_test=obj['ecg_test']\n",
    "ppg_train=obj['ppg_train']\n",
    "ppg_valid=obj['ppg_valid']\n",
    "ppg_test=obj['ppg_test']\n",
    "y_train=obj['y_train']\n",
    "y_valid=obj['y_valid']\n",
    "y_test=obj['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effb384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_sqi_train=obj['ecg_sqi_train']\n",
    "ppg_sqi_train=obj['ppg_sqi_train']\n",
    "ecg_sqi_valid=obj['ecg_sqi_valid']\n",
    "ppg_sqi_valid=obj['ppg_sqi_valid']\n",
    "ecg_sqi_test=obj['ecg_sqi_test']\n",
    "ppg_sqi_test=obj['ppg_sqi_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17c85ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8696450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.isnan(ecg_train).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6cda8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06185318,  0.06131563,  0.06131563, ...,  0.06239073,\n",
       "         0.06239073,  0.06239073],\n",
       "       [ 0.05970299,  0.05970299,  0.05970299, ...,  0.06024053,\n",
       "         0.06024053,  0.05970299],\n",
       "       [ 0.05378996,  0.05378996,  0.05325241, ...,  0.06077808,\n",
       "         0.06131563,  0.06131563],\n",
       "       ...,\n",
       "       [ 0.79320376,  0.73671454,  0.67215543, ..., -0.53686063,\n",
       "        -0.49577756, -0.43195208],\n",
       "       [-0.1949908 , -0.19792531, -0.1920563 , ...,  0.62080159,\n",
       "         0.57531676,  0.52763105],\n",
       "       [ 0.29580516,  0.34422449,  0.39337745, ..., -0.26028354,\n",
       "        -0.25001277, -0.24561101]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "098b5cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_sqi_train_mean=np.mean(ecg_sqi_train, axis=0)\n",
    "ecg_sqi_train_std=np.std(ecg_sqi_train, axis=0)\n",
    "\n",
    "for i in range(ecg_sqi_train.shape[0]):\n",
    "    ecg_sqi_train[i,:]=(ecg_sqi_train[i,:]-ecg_sqi_train_mean)/ecg_sqi_train_std\n",
    "    \n",
    "for i in range(ecg_sqi_valid.shape[0]):\n",
    "    ecg_sqi_valid[i,:]=(ecg_sqi_valid[i,:]-ecg_sqi_train_mean)/ecg_sqi_train_std\n",
    "    \n",
    "for i in range(ecg_sqi_test.shape[0]):\n",
    "    ecg_sqi_test[i,:]=(ecg_sqi_test[i,:]-ecg_sqi_train_mean)/ecg_sqi_train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf554fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_sqi_train_mean=np.mean(ppg_sqi_train, axis=0)\n",
    "ppg_sqi_train_std=np.std(ppg_sqi_train, axis=0)\n",
    "\n",
    "for i in range(ppg_sqi_train.shape[0]):\n",
    "    ppg_sqi_train[i,:]=(ppg_sqi_train[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n",
    "    \n",
    "for i in range(ppg_sqi_valid.shape[0]):\n",
    "    ppg_sqi_valid[i,:]=(ppg_sqi_valid[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n",
    "    \n",
    "for i in range(ppg_sqi_test.shape[0]):\n",
    "    ppg_sqi_test[i,:]=(ppg_sqi_test[i,:]-ppg_sqi_train_mean)/ppg_sqi_train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f85a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train=np.expand_dims(ecg_train, axis=1)\n",
    "ecg_valid=np.expand_dims(ecg_valid, axis=1)\n",
    "ppg_train=np.expand_dims(ppg_train, axis=1)\n",
    "ppg_valid=np.expand_dims(ppg_valid, axis=1)\n",
    "\n",
    "ecg_sqi_train=np.expand_dims(ecg_sqi_train, axis=1)\n",
    "ecg_sqi_valid=np.expand_dims(ecg_sqi_valid, axis=1)\n",
    "ppg_sqi_train=np.expand_dims(ppg_sqi_train, axis=1)\n",
    "ppg_sqi_valid=np.expand_dims(ppg_sqi_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d436ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_test=np.expand_dims(ecg_test, axis=1)\n",
    "ppg_test=np.expand_dims(ppg_test, axis=1)\n",
    "\n",
    "\n",
    "ecg_sqi_test=np.expand_dims(ecg_sqi_test, axis=1)\n",
    "ppg_sqi_test=np.expand_dims(ppg_sqi_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886d29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d141a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_train_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_train_num = y_train_encoder.fit_transform(y_train)\n",
    "y_train_wide = to_categorical(y_train_num, num_classes)\n",
    "\n",
    "y_valid_num = y_train_encoder.fit_transform(y_valid)\n",
    "y_valid_wide = to_categorical(y_valid_num, num_classes)\n",
    "\n",
    "y_test_num = y_train_encoder.fit_transform(y_test)\n",
    "y_test_wide = to_categorical(y_test_num, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20a91658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fusion_model_v3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #ecg alone\n",
    "        self.bn1_ecg=nn.BatchNorm1d(1)\n",
    "        self.conv1_ecg = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ecg = nn.LeakyReLU()\n",
    "        self.max1_ecg = nn.MaxPool1d(2)\n",
    "        self.drop1_ecg=nn.Dropout(0.25)\n",
    "        self.conv2_ecg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ecg = nn.MaxPool1d(2)\n",
    "        self.relu2_ecg = nn.LeakyReLU()\n",
    "        self.drop2_ecg=nn.Dropout(0.25)\n",
    "        self.conv3_ecg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ecg=nn.Dropout(0.25)\n",
    "        self.conv4_ecg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ecg = nn.MaxPool1d(2)\n",
    "        self.relu4_ecg = nn.LeakyReLU()\n",
    "        self.bn2_ecg=nn.BatchNorm1d(5)\n",
    "        self.flat_ecg=nn.Flatten()\n",
    "        self.drop4_ecg=nn.Dropout(0.25)\n",
    "        self.linear1_ecg=nn.Linear(660,2)\n",
    "        self.softm_ecg=nn.Softmax()\n",
    "        \n",
    "        #ppg alone\n",
    "        self.bn1_ppg=nn.BatchNorm1d(1)\n",
    "        self.conv1_ppg = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ppg = nn.LeakyReLU()\n",
    "        self.max1_ppg = nn.MaxPool1d(2)\n",
    "        self.drop1_ppg=nn.Dropout(0.25)\n",
    "        self.conv2_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ppg = nn.MaxPool1d(2)\n",
    "        self.relu2_ppg = nn.LeakyReLU()\n",
    "        self.drop2_ppg=nn.Dropout(0.25)\n",
    "        self.conv3_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ppg=nn.Dropout(0.25)\n",
    "        self.conv4_ppg = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ppg = nn.MaxPool1d(2)\n",
    "        self.relu4_ppg = nn.LeakyReLU()\n",
    "        self.bn2_ppg=nn.BatchNorm1d(5)\n",
    "        self.flat_ppg=nn.Flatten()\n",
    "        self.drop4_ppg=nn.Dropout(0.25)\n",
    "        self.linear1_ppg=nn.Linear(660,2)\n",
    "        self.softm_ppg=nn.Softmax()\n",
    "        \n",
    "        #centre\n",
    "        self.linear1_centre_ecg=nn.Conv1d(in_channels=1, out_channels=1, kernel_size=10, stride=1, padding='same')\n",
    "        self.linear1_centre_ppg=nn.Conv1d(in_channels=1, out_channels=1, kernel_size=10, stride=1, padding='same')\n",
    "        self.tanh1_ecg = nn.LeakyReLU()\n",
    "        self.tanh1_ppg = nn.LeakyReLU()\n",
    "        self.w1_centre=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        #self.w2_centre=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.bn1_centre=nn.BatchNorm1d(1)\n",
    "        self.conv1_centre = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_centre = nn.Sigmoid()\n",
    "        \n",
    "        self.alpha1=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.max1_centre = nn.MaxPool1d(2)\n",
    "        self.drop1_centre=nn.Dropout(0.25)\n",
    "        self.conv2_centre = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_centre = nn.MaxPool1d(2)\n",
    "        self.relu2_centre = nn.Sigmoid()\n",
    "        \n",
    "        self.alpha2=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.drop2_centre=nn.Dropout(0.25)\n",
    "        self.conv3_centre = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_centre=nn.Dropout(0.25)\n",
    "        self.conv4_centre = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_centre = nn.MaxPool1d(2)\n",
    "        self.relu4_centre = nn.Sigmoid()\n",
    "        \n",
    "        self.alpha3=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.bn2_centre=nn.BatchNorm1d(5)\n",
    "        self.flat_centre=nn.Flatten()\n",
    "        \n",
    "        self.alpha4=torch.nn.Parameter(torch.tensor(0.5))\n",
    "        \n",
    "        self.drop4_centre=nn.Dropout(0.25)\n",
    "        self.linear1_centre=nn.Linear(660,2)\n",
    "        self.softm_centre=nn.Softmax()\n",
    "        \n",
    "        #ecgsqi\n",
    "        self.bn1_ecgsqi=nn.BatchNorm1d(1)\n",
    "        self.conv1_ecgsqi = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ecgsqi = nn.LeakyReLU()\n",
    "        self.max1_ecgsqi = nn.MaxPool1d(2)\n",
    "        self.drop1_ecgsqi=nn.Dropout(0.25)\n",
    "        self.conv2_ecgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ecgsqi = nn.MaxPool1d(2)\n",
    "        self.relu2_ecgsqi = nn.LeakyReLU()\n",
    "        self.drop2_ecgsqi=nn.Dropout(0.25)\n",
    "        self.conv3_ecgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ecgsqi=nn.Dropout(0.25)\n",
    "        self.conv4_ecgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ecgsqi = nn.MaxPool1d(2)\n",
    "        self.relu4_ecgsqi = nn.LeakyReLU()\n",
    "        self.bn2_ecgsqi=nn.BatchNorm1d(5)\n",
    "        self.flat_ecgsqi=nn.Flatten()\n",
    "        \n",
    "        #ppgsqi\n",
    "        self.bn1_ppgsqi=nn.BatchNorm1d(1)\n",
    "        self.conv1_ppgsqi = nn.Conv1d(in_channels=1, out_channels=5, kernel_size=30, stride=2)\n",
    "        self.relu1_ppgsqi = nn.LeakyReLU()\n",
    "        self.max1_ppgsqi = nn.MaxPool1d(2)\n",
    "        self.drop1_ppgsqi=nn.Dropout(0.25)\n",
    "        self.conv2_ppgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=25, stride=1)\n",
    "        self.max2_ppgsqi = nn.MaxPool1d(2)\n",
    "        self.relu2_ppgsqi = nn.LeakyReLU()\n",
    "        self.drop2_ppgsqi=nn.Dropout(0.25)\n",
    "        self.conv3_ppgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=20, stride=1)\n",
    "        self.drop3_ppgsqi=nn.Dropout(0.25)\n",
    "        self.conv4_ppgsqi = nn.Conv1d(in_channels=5, out_channels=5, kernel_size=15, stride=1)\n",
    "        self.max4_ppgsqi = nn.MaxPool1d(2)\n",
    "        self.relu4_ppgsqi = nn.LeakyReLU()\n",
    "        self.bn2_ppgsqi=nn.BatchNorm1d(5)\n",
    "        self.flat_ppgsqi=nn.Flatten()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    def forward(self, ecg, ppg, ecgsqi, ppgsqi):\n",
    "        \n",
    "        ### ecg\n",
    "        out_ecg_bn1=self.bn1_ecg(ecg)\n",
    "        out_ecg_conv1= self.conv1_ecg(out_ecg_bn1)\n",
    "        out_ecg_relu1 = self.relu1_ecg(out_ecg_conv1)\n",
    "        out_ecg_max1=self.max1_ecg(out_ecg_relu1)\n",
    "        out_ecg_drop1=self.drop1_ecg(out_ecg_max1)\n",
    "        out_ecg_conv2=self.conv2_ecg(out_ecg_drop1)\n",
    "        out_ecg_max2=self.max2_ecg(out_ecg_conv2)\n",
    "        out_ecg_relu2=self.relu2_ecg(out_ecg_max2)\n",
    "        out_ecg_drop2=self.drop2_ecg(out_ecg_relu2)\n",
    "        out_ecg_conv3=self.conv3_ecg(out_ecg_drop2)\n",
    "        out_ecg_drop3=self.drop3_ecg(out_ecg_conv3)\n",
    "        out_ecg_conv4=self.conv4_ecg(out_ecg_drop3)\n",
    "        out_ecg_max4=self.max4_ecg(out_ecg_conv4)\n",
    "        out_ecg_relu4=self.relu4_ecg(out_ecg_max4)\n",
    "        out_ecg_bn2=self.bn2_ecg(out_ecg_relu4)\n",
    "        out_ecg_flat=self.flat_ecg(out_ecg_bn2)\n",
    "        out_ecg_drop4=self.drop4_ecg(out_ecg_flat)\n",
    "        out_ecg_linear=self.linear1_ecg(out_ecg_drop4)\n",
    "        out_ecg_softm=self.softm_ecg(out_ecg_linear)\n",
    "        \n",
    "        ### ppg\n",
    "        out_ppg_bn1=self.bn1_ppg(ppg)\n",
    "        out_ppg_conv1= self.conv1_ppg(out_ppg_bn1)\n",
    "        out_ppg_relu1 = self.relu1_ppg(out_ppg_conv1)\n",
    "        out_ppg_max1=self.max1_ppg(out_ppg_relu1)\n",
    "        out_ppg_drop1=self.drop1_ppg(out_ppg_max1)\n",
    "        out_ppg_conv2=self.conv2_ppg(out_ppg_drop1)\n",
    "        out_ppg_max2=self.max2_ppg(out_ppg_conv2)\n",
    "        out_ppg_relu2=self.relu2_ppg(out_ppg_max2)\n",
    "        out_ppg_drop2=self.drop2_ppg(out_ppg_relu2)\n",
    "        out_ppg_conv3=self.conv3_ppg(out_ppg_drop2)\n",
    "        out_ppg_drop3=self.drop3_ppg(out_ppg_conv3)\n",
    "        out_ppg_conv4=self.conv4_ppg(out_ppg_drop3)\n",
    "        out_ppg_max4=self.max4_ppg(out_ppg_conv4)\n",
    "        out_ppg_relu4=self.relu4_ppg(out_ppg_max4)\n",
    "        out_ppg_bn2=self.bn2_ppg(out_ppg_relu4)\n",
    "        out_ppg_flat=self.flat_ppg(out_ppg_bn2)\n",
    "        out_ppg_drop4=self.drop4_ppg(out_ppg_flat)\n",
    "        out_ppg_linear=self.linear1_ppg(out_ppg_drop4)\n",
    "        out_ppg_softm=self.softm_ppg(out_ppg_linear)\n",
    "        \n",
    "        \n",
    "        ### ecgsqi\n",
    "        out_ecgsqi_bn1=self.bn1_ecgsqi(ecgsqi)\n",
    "        out_ecgsqi_conv1= self.conv1_ecgsqi(out_ecgsqi_bn1)\n",
    "        out_ecgsqi_relu1 = self.relu1_ecgsqi(out_ecgsqi_conv1)\n",
    "        out_ecgsqi_max1=self.max1_ecgsqi(out_ecgsqi_relu1)\n",
    "        out_ecgsqi_drop1=self.drop1_ecgsqi(out_ecgsqi_max1)\n",
    "        out_ecgsqi_conv2=self.conv2_ecgsqi(out_ecgsqi_drop1)\n",
    "        out_ecgsqi_max2=self.max2_ecgsqi(out_ecgsqi_conv2)\n",
    "        out_ecgsqi_relu2=self.relu2_ecgsqi(out_ecgsqi_max2)\n",
    "        out_ecgsqi_drop2=self.drop2_ecgsqi(out_ecgsqi_relu2)\n",
    "        out_ecgsqi_conv3=self.conv3_ecgsqi(out_ecgsqi_drop2)\n",
    "        out_ecgsqi_drop3=self.drop3_ecgsqi(out_ecgsqi_conv3)\n",
    "        out_ecgsqi_conv4=self.conv4_ecgsqi(out_ecgsqi_drop3)\n",
    "        out_ecgsqi_max4=self.max4_ecgsqi(out_ecgsqi_conv4)\n",
    "        out_ecgsqi_relu4=self.relu4_ecgsqi(out_ecgsqi_max4)\n",
    "        out_ecgsqi_bn2=self.bn2_ecgsqi(out_ecgsqi_relu4)\n",
    "        out_ecgsqi_flat=self.flat_ecgsqi(out_ecgsqi_bn2)\n",
    "\n",
    "        ### ppgsqi\n",
    "        out_ppgsqi_bn1=self.bn1_ppgsqi(ppgsqi)\n",
    "        out_ppgsqi_conv1= self.conv1_ppgsqi(out_ppgsqi_bn1)\n",
    "        out_ppgsqi_relu1 = self.relu1_ppgsqi(out_ppgsqi_conv1)\n",
    "        out_ppgsqi_max1=self.max1_ppgsqi(out_ppgsqi_relu1)\n",
    "        out_ppgsqi_drop1=self.drop1_ppgsqi(out_ppgsqi_max1)\n",
    "        out_ppgsqi_conv2=self.conv2_ppgsqi(out_ppgsqi_drop1)\n",
    "        out_ppgsqi_max2=self.max2_ppgsqi(out_ppgsqi_conv2)\n",
    "        out_ppgsqi_relu2=self.relu2_ppgsqi(out_ppgsqi_max2)\n",
    "        out_ppgsqi_drop2=self.drop2_ppgsqi(out_ppgsqi_relu2)\n",
    "        out_ppgsqi_conv3=self.conv3_ppgsqi(out_ppgsqi_drop2)\n",
    "        out_ppgsqi_drop3=self.drop3_ppgsqi(out_ppgsqi_conv3)\n",
    "        out_ppgsqi_conv4=self.conv4_ppgsqi(out_ppgsqi_drop3)\n",
    "        out_ppgsqi_max4=self.max4_ppgsqi(out_ppgsqi_conv4)\n",
    "        out_ppgsqi_relu4=self.relu4_ppgsqi(out_ppgsqi_max4)\n",
    "        out_ppgsqi_bn2=self.bn2_ppgsqi(out_ppgsqi_relu4)\n",
    "        out_ppgsqi_flat=self.flat_ppgsqi(out_ppgsqi_bn2)\n",
    "        \n",
    "        ####weighted_sqis\n",
    "        out_ecgsqi_relu1_w=out_ecgsqi_relu1.div(out_ecgsqi_relu1+out_ppgsqi_relu1+1e-6)\n",
    "        out_ppgsqi_relu1_w=out_ppgsqi_relu1.div(out_ecgsqi_relu1+out_ppgsqi_relu1+1e-6)\n",
    "        \n",
    "        out_ecgsqi_relu2_w=out_ecgsqi_relu2.div(out_ecgsqi_relu2+out_ppgsqi_relu2+1e-6)\n",
    "        out_ppgsqi_relu2_w=out_ppgsqi_relu2.div(out_ecgsqi_relu2+out_ppgsqi_relu2+1e-6)\n",
    "        \n",
    "        out_ecgsqi_relu4_w=out_ecgsqi_relu4.div(out_ecgsqi_relu4+out_ppgsqi_relu4+1e-6)\n",
    "        out_ppgsqi_relu4_w=out_ppgsqi_relu4.div(out_ecgsqi_relu4+out_ppgsqi_relu4+1e-6)\n",
    "        \n",
    "        out_ecgsqi_flat_w=out_ecgsqi_flat.div(out_ecgsqi_flat+out_ppgsqi_flat+1e-6)\n",
    "        out_ppgsqi_flat_w=out_ppgsqi_flat.div(out_ecgsqi_flat+out_ppgsqi_flat+1e-6)\n",
    "        \n",
    "        ### centre\n",
    "        \n",
    "        out_centre_ecg=self.linear1_centre_ecg(ecg)\n",
    "        out_centre_ppg=self.linear1_centre_ppg(ppg)\n",
    "        out_centre_ecg=self.tanh1_ecg(out_centre_ecg)\n",
    "        out_centre_ppg=self.tanh1_ecg(out_centre_ppg)\n",
    "        \n",
    "        \n",
    "        out_init=torch.mul(out_centre_ecg,self.w1_centre)+torch.mul(out_centre_ppg,1-self.w1_centre)\n",
    "        \n",
    "        out_centre_bn1=self.bn1_centre(out_init)\n",
    "        out_centre_conv1=self.conv1_centre(out_centre_bn1)\n",
    "        out_centre_relu1=self.relu1_centre(out_centre_conv1)\n",
    "        \n",
    "        out_hidden_1=torch.mul(out_centre_relu1,self.alpha1)+torch.mul((torch.mul(out_ecgsqi_relu1_w,out_ecg_relu1))+(torch.mul(out_ppgsqi_relu1_w,out_ppg_relu1)),(1-self.alpha1))\n",
    "        \n",
    "        out_centre_max1=self.max1_centre(out_hidden_1)\n",
    "        out_centre_drop1=self.drop1_centre(out_centre_max1)\n",
    "        out_centre_conv2=self.conv2_centre(out_centre_drop1)\n",
    "        out_centre_max2=self.max2_centre(out_centre_conv2)\n",
    "        out_centre_relu2=self.relu2_centre(out_centre_max2)\n",
    "                                                                        \n",
    "        out_hidden_2=torch.mul(out_centre_relu2,self.alpha2)+torch.mul((torch.mul(out_ecgsqi_relu2_w,out_ecg_relu2))+(torch.mul(out_ppgsqi_relu2_w,out_ppg_relu2)),(1-self.alpha2))\n",
    "        ################\n",
    "        out_centre_drop2=self.drop2_centre(out_hidden_2)\n",
    "        out_centre_conv3=self.conv3_centre(out_centre_drop2)\n",
    "        out_centre_drop3=self.drop3_centre(out_centre_conv3)\n",
    "        out_centre_conv4=self.conv4_centre(out_centre_drop3)\n",
    "        out_centre_max4=self.max4_centre(out_centre_conv4)\n",
    "        out_centre_relu4=self.relu4_centre(out_centre_max4)\n",
    "                                                                        \n",
    "        out_hidden_3=torch.mul(out_centre_relu4,self.alpha3)+torch.mul((torch.mul(out_ecgsqi_relu4_w,out_ecg_relu4))+(torch.mul(out_ppgsqi_relu4_w,out_ppg_relu4)),(1-self.alpha3))                                                                \n",
    "        \n",
    "        out_centre_bn2=self.bn2_centre(out_hidden_3)\n",
    "        out_centre_flatten=self.flat_centre(out_centre_bn2)\n",
    "                                                                        \n",
    "        out_hidden_4= torch.mul(out_centre_flatten,self.alpha4)+torch.mul((torch.mul(out_ecgsqi_flat_w,out_ecg_flat))+(torch.mul(out_ppgsqi_flat_w,out_ppg_flat)),(1-self.alpha4))                                                                \n",
    "                                                                       \n",
    "        out_centre_drop4=self.drop4_centre(out_hidden_4)\n",
    "        out_centre_linear=self.linear1_centre(out_centre_drop4)\n",
    "        out_centre_softm=self.softm_centre(out_centre_linear)\n",
    "\n",
    "        return out_centre_softm, out_ppg_softm, out_ecg_softm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f580b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dc27ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fusion = fusion_model_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57f99e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ecg_train = torch.from_numpy(ecg_train)\n",
    "ecg_valid=torch.from_numpy(ecg_valid)\n",
    "ecg_test=torch.from_numpy(ecg_test)\n",
    "\n",
    "ppg_train = torch.from_numpy(ppg_train)\n",
    "ppg_valid=torch.from_numpy(ppg_valid)\n",
    "ppg_test = torch.from_numpy(ppg_test)\n",
    "\n",
    "ecg_sqi_train = torch.from_numpy(ecg_sqi_train)\n",
    "ecg_sqi_valid=torch.from_numpy(ecg_sqi_valid)\n",
    "ecg_sqi_test = torch.from_numpy(ecg_sqi_test)\n",
    "\n",
    "ppg_sqi_train = torch.from_numpy(ppg_sqi_train)\n",
    "ppg_sqi_valid=torch.from_numpy(ppg_sqi_valid)\n",
    "ppg_sqi_test = torch.from_numpy(ppg_sqi_test)\n",
    "\n",
    "y_train_wide = torch.from_numpy(y_train_wide)\n",
    "y_valid_wide = torch.from_numpy(y_valid_wide)\n",
    "y_test_wide = torch.from_numpy(y_test_wide)\n",
    "y_train_num = torch.from_numpy(y_train_num)\n",
    "y_valid_num = torch.from_numpy(y_valid_num)\n",
    "y_test_num = torch.from_numpy(y_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4044d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_fusion = model_fusion.cuda()\n",
    "#if torch.cuda.is_available():\n",
    "#    ecg_valid, y_valid_num, ppg_valid, ecg_sqi_valid, ppg_sqi_valid = ecg_valid.cuda(), y_valid_num.cuda(), ppg_valid.cuda(), ecg_sqi_valid.cuda(), ppg_sqi_valid.cuda()\n",
    "    #ecg_train, y_train_num, ppg_train, ecg_sqi_train, ppg_sqi_train = ecg_train.cuda(), y_train_num.cuda(), ppg_train.cuda(), ecg_sqi_train.cuda(), ppg_sqi_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15413a38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\torch\\nn\\modules\\conv.py:295: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ..\\aten\\src\\ATen\\native\\Convolution.cpp:660.)\n",
      "  self.padding, self.dilation, self.groups)\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 1.1615912375369466 \t \t Accuracy = 60.91773986816406, \t Validation Loss: 0.7110519857085936, \t Validation accuracy: 51.39802932739258\n",
      "Validation Loss Decreased(inf--->0.711052) \t Saving The Model\n",
      "Starting epoch 2\n",
      "Epoch 2 \t\t Training Loss: 0.9899752035709029 \t \t Accuracy = 78.39435577392578, \t Validation Loss: 0.49641428408566973, \t Validation accuracy: 82.80075073242188\n",
      "Validation Loss Decreased(0.711052--->0.496414) \t Saving The Model\n",
      "Starting epoch 3\n",
      "Epoch 3 \t\t Training Loss: 0.9174149932998016 \t \t Accuracy = 83.82972717285156, \t Validation Loss: 0.476081118946187, \t Validation accuracy: 83.8757095336914\n",
      "Validation Loss Decreased(0.496414--->0.476081) \t Saving The Model\n",
      "Starting epoch 4\n",
      "Epoch 4 \t\t Training Loss: 0.8843207408751088 \t \t Accuracy = 85.2072982788086, \t Validation Loss: 0.45808190996186776, \t Validation accuracy: 86.03736114501953\n",
      "Validation Loss Decreased(0.476081--->0.458082) \t Saving The Model\n",
      "Starting epoch 5\n",
      "Epoch 5 \t\t Training Loss: 0.8524021826040252 \t \t Accuracy = 86.3851318359375, \t Validation Loss: 0.4509508400632624, \t Validation accuracy: 86.52490997314453\n",
      "Validation Loss Decreased(0.458082--->0.450951) \t Saving The Model\n",
      "Starting epoch 6\n",
      "Epoch 6 \t\t Training Loss: 0.8322445439608922 \t \t Accuracy = 86.79634094238281, \t Validation Loss: 0.44684242627076937, \t Validation accuracy: 86.84210968017578\n",
      "Validation Loss Decreased(0.450951--->0.446842) \t Saving The Model\n",
      "Starting epoch 7\n",
      "Epoch 7 \t\t Training Loss: 0.820882245506111 \t \t Accuracy = 86.7640380859375, \t Validation Loss: 0.4476149742714843, \t Validation accuracy: 86.70113372802734\n",
      "Starting epoch 8\n",
      "Epoch 8 \t\t Training Loss: 0.8137583153504402 \t \t Accuracy = 86.4416732788086, \t Validation Loss: 0.45176116520898385, \t Validation accuracy: 86.3839340209961\n",
      "Starting epoch 9\n",
      "Epoch 9 \t\t Training Loss: 0.8068972662987566 \t \t Accuracy = 86.38880157470703, \t Validation Loss: 0.44964448785224154, \t Validation accuracy: 86.38980102539062\n",
      "Starting epoch 10\n",
      "Epoch 10 \t\t Training Loss: 0.7981736069279057 \t \t Accuracy = 86.66710662841797, \t Validation Loss: 0.4475073230545423, \t Validation accuracy: 86.60127258300781\n",
      "Starting epoch 11\n",
      "Epoch 11 \t\t Training Loss: 0.7921255984504644 \t \t Accuracy = 86.71483612060547, \t Validation Loss: 0.4471038930248796, \t Validation accuracy: 86.63651275634766\n",
      "Starting epoch 12\n",
      "Epoch 12 \t\t Training Loss: 0.7863269746443606 \t \t Accuracy = 86.77064514160156, \t Validation Loss: 0.44267641190896956, \t Validation accuracy: 87.1475601196289\n",
      "Validation Loss Decreased(0.446842--->0.442676) \t Saving The Model\n",
      "Starting epoch 13\n",
      "Epoch 13 \t\t Training Loss: 0.7775520348039112 \t \t Accuracy = 87.07464599609375, \t Validation Loss: 0.44307411553566917, \t Validation accuracy: 87.12406158447266\n",
      "Starting epoch 14\n",
      "Epoch 14 \t\t Training Loss: 0.7705863686768633 \t \t Accuracy = 87.24134063720703, \t Validation Loss: 0.4411125111649608, \t Validation accuracy: 87.27678680419922\n",
      "Validation Loss Decreased(0.442676--->0.441113) \t Saving The Model\n",
      "Starting epoch 15\n",
      "Epoch 15 \t\t Training Loss: 0.782392572359483 \t \t Accuracy = 85.48486328125, \t Validation Loss: 0.5670355868618391, \t Validation accuracy: 75.71663665771484\n",
      "Starting epoch 16\n",
      "Epoch 16 \t\t Training Loss: 0.7831576271612841 \t \t Accuracy = 85.47752380371094, \t Validation Loss: 0.4187420770438791, \t Validation accuracy: 89.4913101196289\n",
      "Validation Loss Decreased(0.441113--->0.418742) \t Saving The Model\n",
      "Starting epoch 17\n",
      "Epoch 17 \t\t Training Loss: 0.7219480368259706 \t \t Accuracy = 91.62003326416016, \t Validation Loss: 0.3783959561621236, \t Validation accuracy: 93.96734619140625\n",
      "Validation Loss Decreased(0.418742--->0.378396) \t Saving The Model\n",
      "Starting epoch 18\n",
      "Epoch 18 \t\t Training Loss: 0.7421035825842082 \t \t Accuracy = 89.373779296875, \t Validation Loss: 0.38126510102846467, \t Validation accuracy: 93.45042419433594\n",
      "Starting epoch 19\n",
      "Epoch 19 \t\t Training Loss: 0.7130803117402514 \t \t Accuracy = 92.07677459716797, \t Validation Loss: 0.5432459623144384, \t Validation accuracy: 77.0089340209961\n",
      "Starting epoch 20\n",
      "Epoch 20 \t\t Training Loss: 0.7379190632023085 \t \t Accuracy = 89.30034637451172, \t Validation Loss: 0.405565129037489, \t Validation accuracy: 91.2593994140625\n",
      "Starting epoch 21\n",
      "Epoch 21 \t\t Training Loss: 0.860810697624894 \t \t Accuracy = 76.64155578613281, \t Validation Loss: 0.419840964831804, \t Validation accuracy: 89.33858489990234\n",
      "Starting epoch 22\n",
      "Epoch 22 \t\t Training Loss: 0.8224733665557509 \t \t Accuracy = 80.32706451416016, \t Validation Loss: 0.5360780624966872, \t Validation accuracy: 77.44361114501953\n",
      "Starting epoch 23\n",
      "Epoch 23 \t\t Training Loss: 0.8477766812547929 \t \t Accuracy = 77.57485961914062, \t Validation Loss: 0.5357118001458241, \t Validation accuracy: 77.52584838867188\n",
      "Starting epoch 24\n",
      "Epoch 24 \t\t Training Loss: 0.8167194345951977 \t \t Accuracy = 80.52165222167969, \t Validation Loss: 0.4594806931172198, \t Validation accuracy: 85.22086334228516\n",
      "Starting epoch 25\n",
      "Epoch 25 \t\t Training Loss: 0.8172783322660322 \t \t Accuracy = 80.3689193725586, \t Validation Loss: 0.5734174532151362, \t Validation accuracy: 73.6900863647461\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "#loss_function = nn.functional.binary_cross_entropy\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_fusion.parameters(), lr=1.5e-5)\n",
    "batch_size=32\n",
    "n_batches=np.ceil(len(ecg_train)/batch_size).astype(np.int64)\n",
    "valid_batch_size=100\n",
    "valid_batches=np.ceil(len(ecg_valid)/valid_batch_size).astype(np.int64) \n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(0, 25): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    current_tot_loss=0.0\n",
    "    correct=0\n",
    "    i=0\n",
    "    # Iterate over the DataLoader for training data\n",
    "    ind_list = list(range(len(ecg_train)))\n",
    "    shuffle(ind_list)\n",
    "    #train_new  = train[ind_list, :,:,:]\n",
    "    #target_new = target[ind_list,]\n",
    "    while i<n_batches:\n",
    "\n",
    "          # Get inputs\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_wide[i*batch_size:(i+1)*batch_size,]\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_num[i*batch_size:(i+1)*batch_size,]\n",
    "        local_ecg, local_y, local_ppg, local_ecg_sqi,local_ppg_sqi = ecg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),y_train_num[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ppg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ecg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),ppg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda()\n",
    "        #if torch.cuda.is_available():\n",
    "        #    local_X, local_y = local_X.cuda(), local_y.cuda()\n",
    "\n",
    "          # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs_c, outputs_ecg, outputs_ppg = model_fusion(local_ecg.float(),local_ppg.float(),local_ecg_sqi.float(), local_ppg_sqi.float())\n",
    "        \n",
    "        \n",
    "\n",
    "        # Compute loss\n",
    "        loss1 = loss_function(outputs_c, local_y)\n",
    "        #loss2 = loss_function(outputs_ecg, local_y)\n",
    "        #loss3 = loss_function(outputs_ppg, local_y)\n",
    "        #loss=(loss1+loss2+loss3)/3\n",
    "        loss=loss1\n",
    "        #print(loss)\n",
    "        \n",
    "        #loss = loss_function(outputs, local_y.float())\n",
    "        l2_lambda = 0.01\n",
    "        l2_reg = torch.tensor(0.).cuda()\n",
    "        for param in model_fusion.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += l2_lambda * l2_reg\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        output = outputs_c.clone()\n",
    "        output= torch.argmax(output, axis=1)\n",
    "        \n",
    "        correct += (output == local_y).float().sum()\n",
    "\n",
    "        # Print statistics\n",
    "        \n",
    "        #current_loss += loss.item()\n",
    "        current_tot_loss+=loss.item()\n",
    "       # if i % 20 == 19:\n",
    "       #     print('Loss after mini-batch %5d: %.3f' %\n",
    "       #         (i + 1, current_loss / 20))\n",
    "       #     current_loss = 0.0\n",
    "        i=i+1\n",
    "        \n",
    "    \n",
    "    \n",
    "    correct_valid=0\n",
    "    current_valid_loss = 0.0\n",
    "    current_valid_tot_loss=0.0\n",
    "    j=0\n",
    "    while j<valid_batches:\n",
    "        model_fusion.eval()     # Optional when not using Model Specific layer\n",
    "        local_ecg_valid, local_y_valid, local_ppg_valid, local_ecg_sqi_valid,local_ppg_sqi_valid = ecg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),y_valid_num[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ppg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ecg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),ppg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda()\n",
    "        target, target2, target3 = model_fusion(local_ecg_valid.float(),local_ppg_valid.float(),local_ecg_sqi_valid.float(), local_ppg_sqi_valid.float())\n",
    "        loss1 = loss_function(target,local_y_valid)\n",
    "        #loss2 = loss_function(target2,local_y_valid)\n",
    "        #loss3 = loss_function(target3,local_y_valid)\n",
    "        loss=loss1\n",
    "        #loss=(loss1+loss2+loss3)/3\n",
    "        current_valid_loss+=loss.item()\n",
    "        #valid_loss = loss.item() \n",
    "        target= torch.argmax(target, axis=1)\n",
    "        correct_valid += (target == local_y_valid).float().sum()\n",
    "        j=j+1\n",
    "    \n",
    "    #print(correct)\n",
    "    #print(current_tot_loss)\n",
    "    accuracy = 100 * correct / len(ecg_train)\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {current_tot_loss / n_batches} \\t \\t Accuracy = {accuracy}, \\t Validation Loss: {current_valid_loss/ valid_batches}, \\t Validation accuracy: {100*correct_valid/len(ecg_valid)}')\n",
    "    \n",
    "    if min_valid_loss > (current_valid_loss/valid_batches):\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{current_valid_loss/valid_batches:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = (current_valid_loss/valid_batches)\n",
    "        # Saving State Dict\n",
    "        torch.save(model_fusion.state_dict(), 'saved_model_fusion_no_noise_0.01.pth')\n",
    "        \n",
    "    \n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb2fcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fusion_model_v3(\n",
       "  (bn1_ecg): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ecg): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ecg): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ecg): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ecg): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ecg): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ecg): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_ecg): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_ecg): Softmax(dim=None)\n",
       "  (bn1_ppg): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ppg): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ppg): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ppg): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ppg): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ppg): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ppg): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_ppg): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_ppg): Softmax(dim=None)\n",
       "  (linear1_centre_ecg): Conv1d(1, 1, kernel_size=(10,), stride=(1,), padding=same)\n",
       "  (linear1_centre_ppg): Conv1d(1, 1, kernel_size=(10,), stride=(1,), padding=same)\n",
       "  (tanh1_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (tanh1_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn1_centre): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_centre): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_centre): Sigmoid()\n",
       "  (max1_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_centre): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_centre): Sigmoid()\n",
       "  (drop2_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_centre): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_centre): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_centre): Sigmoid()\n",
       "  (bn2_centre): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_centre): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_centre): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_centre): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_centre): Softmax(dim=None)\n",
       "  (bn1_ecgsqi): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ecgsqi): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ecgsqi): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ecgsqi): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ecgsqi): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ecgsqi): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ecgsqi): Flatten(start_dim=1, end_dim=-1)\n",
       "  (bn1_ppgsqi): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ppgsqi): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ppgsqi): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ppgsqi): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ppgsqi): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ppgsqi): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ppgsqi): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fusion.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "944d399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fusion_model_v3(\n",
       "  (bn1_ecg): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ecg): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ecg): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ecg): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ecg): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ecg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ecg): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ecg): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_ecg): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_ecg): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_ecg): Softmax(dim=None)\n",
       "  (bn1_ppg): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ppg): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ppg): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ppg): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ppg): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ppg): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ppg): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ppg): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_ppg): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_ppg): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_ppg): Softmax(dim=None)\n",
       "  (linear1_centre_ecg): Conv1d(1, 1, kernel_size=(10,), stride=(1,), padding=same)\n",
       "  (linear1_centre_ppg): Conv1d(1, 1, kernel_size=(10,), stride=(1,), padding=same)\n",
       "  (tanh1_ecg): LeakyReLU(negative_slope=0.01)\n",
       "  (tanh1_ppg): LeakyReLU(negative_slope=0.01)\n",
       "  (bn1_centre): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_centre): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_centre): Sigmoid()\n",
       "  (max1_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_centre): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_centre): Sigmoid()\n",
       "  (drop2_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_centre): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_centre): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_centre): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_centre): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_centre): Sigmoid()\n",
       "  (bn2_centre): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_centre): Flatten(start_dim=1, end_dim=-1)\n",
       "  (drop4_centre): Dropout(p=0.25, inplace=False)\n",
       "  (linear1_centre): Linear(in_features=660, out_features=2, bias=True)\n",
       "  (softm_centre): Softmax(dim=None)\n",
       "  (bn1_ecgsqi): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ecgsqi): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ecgsqi): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ecgsqi): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ecgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ecgsqi): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ecgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ecgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ecgsqi): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ecgsqi): Flatten(start_dim=1, end_dim=-1)\n",
       "  (bn1_ppgsqi): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_ppgsqi): Conv1d(1, 5, kernel_size=(30,), stride=(2,))\n",
       "  (relu1_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (max1_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv2_ppgsqi): Conv1d(5, 5, kernel_size=(25,), stride=(1,))\n",
       "  (max2_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (drop2_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv3_ppgsqi): Conv1d(5, 5, kernel_size=(20,), stride=(1,))\n",
       "  (drop3_ppgsqi): Dropout(p=0.25, inplace=False)\n",
       "  (conv4_ppgsqi): Conv1d(5, 5, kernel_size=(15,), stride=(1,))\n",
       "  (max4_ppgsqi): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu4_ppgsqi): LeakyReLU(negative_slope=0.01)\n",
       "  (bn2_ppgsqi): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (flat_ppgsqi): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_saved = fusion_model_v3()\n",
    "model_saved.load_state_dict(torch.load('saved_model_fusion_no_noise_0.01.pth'))\n",
    "model_saved.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cfd7a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9920)\n",
      "[[8435   76]\n",
      " [  35 5413]]\n"
     ]
    }
   ],
   "source": [
    "outputs_test,out1,out2 = model_saved(ecg_test.float(), ppg_test.float(), ecg_sqi_test.float(), ppg_sqi_test.float())\n",
    "outputs_test = outputs_test.clone()\n",
    "outputs_test= torch.argmax(outputs_test, axis=1)\n",
    "\n",
    "        \n",
    "correct = (outputs_test == y_test_num).float().sum()\n",
    "print(correct/len(ecg_test))\n",
    "\n",
    "cm=confusion_matrix(y_test_num.cpu(), outputs_test.cpu())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ff375",
   "metadata": {},
   "source": [
    "## combining losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e14631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bb601e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fusion2 = fusion_model_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b30a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model_fusion2 = model_fusion2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e84f9e65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 1.0686624728395302 \t \t Accuracy = 64.60545349121094, \t Validation Loss: 0.6122625647929677, \t Validation accuracy: 67.84539794921875\n",
      "Validation Loss Decreased(inf--->0.612263) \t Saving The Model\n",
      "Starting epoch 2\n",
      "Epoch 2 \t\t Training Loss: 0.9026984220048538 \t \t Accuracy = 86.59661102294922, \t Validation Loss: 0.4409718604115715, \t Validation accuracy: 90.29605865478516\n",
      "Validation Loss Decreased(0.612263--->0.440972) \t Saving The Model\n",
      "Starting epoch 3\n",
      "Epoch 3 \t\t Training Loss: 0.8082332536578178 \t \t Accuracy = 96.19847106933594, \t Validation Loss: 0.3804342670050281, \t Validation accuracy: 97.4506607055664\n",
      "Validation Loss Decreased(0.440972--->0.380434) \t Saving The Model\n",
      "Starting epoch 4\n",
      "Epoch 4 \t\t Training Loss: 0.7736049332845032 \t \t Accuracy = 97.12443542480469, \t Validation Loss: 0.38345694350220305, \t Validation accuracy: 96.36396026611328\n",
      "Starting epoch 5\n",
      "Epoch 5 \t\t Training Loss: 0.7676027990121367 \t \t Accuracy = 95.27911376953125, \t Validation Loss: 0.3808526381065971, \t Validation accuracy: 96.45794677734375\n",
      "Starting epoch 6\n",
      "Epoch 6 \t\t Training Loss: 0.7527739974088911 \t \t Accuracy = 96.27777099609375, \t Validation Loss: 0.3825929783589659, \t Validation accuracy: 95.78829956054688\n",
      "Starting epoch 7\n",
      "Epoch 7 \t\t Training Loss: 0.7424917539819739 \t \t Accuracy = 96.25868225097656, \t Validation Loss: 0.37683310930491887, \t Validation accuracy: 97.45653533935547\n",
      "Validation Loss Decreased(0.380434--->0.376833) \t Saving The Model\n",
      "Starting epoch 8\n",
      "Epoch 8 \t\t Training Loss: 0.7302248028520131 \t \t Accuracy = 97.34326171875, \t Validation Loss: 0.38445123263269837, \t Validation accuracy: 94.9600601196289\n",
      "Starting epoch 9\n",
      "Epoch 9 \t\t Training Loss: 0.7589343464688251 \t \t Accuracy = 86.16703796386719, \t Validation Loss: 0.4130340720477857, \t Validation accuracy: 86.09022521972656\n",
      "Starting epoch 10\n",
      "Epoch 10 \t\t Training Loss: 0.7482984532791197 \t \t Accuracy = 86.37925720214844, \t Validation Loss: 0.4106662022440057, \t Validation accuracy: 86.60127258300781\n",
      "Starting epoch 11\n",
      "Epoch 11 \t\t Training Loss: 0.7161101133499602 \t \t Accuracy = 93.47270202636719, \t Validation Loss: 0.3936549344955132, \t Validation accuracy: 92.96287536621094\n",
      "Starting epoch 12\n",
      "Epoch 12 \t\t Training Loss: 0.7016528415304601 \t \t Accuracy = 96.13311767578125, \t Validation Loss: 0.37486717209481357, \t Validation accuracy: 97.56227111816406\n",
      "Validation Loss Decreased(0.376833--->0.374867) \t Saving The Model\n",
      "Starting epoch 13\n",
      "Epoch 13 \t\t Training Loss: 0.6868852018413687 \t \t Accuracy = 97.85140228271484, \t Validation Loss: 0.37331978410308125, \t Validation accuracy: 97.95582580566406\n",
      "Validation Loss Decreased(0.374867--->0.373320) \t Saving The Model\n",
      "Starting epoch 14\n",
      "Epoch 14 \t\t Training Loss: 0.6786062103745184 \t \t Accuracy = 98.12677001953125, \t Validation Loss: 0.3721908306517796, \t Validation accuracy: 98.27302551269531\n",
      "Validation Loss Decreased(0.373320--->0.372191) \t Saving The Model\n",
      "Starting epoch 15\n",
      "Epoch 15 \t\t Training Loss: 0.6714814013444391 \t \t Accuracy = 98.34412384033203, \t Validation Loss: 0.37247355343305577, \t Validation accuracy: 98.2906494140625\n",
      "Starting epoch 16\n",
      "Epoch 16 \t\t Training Loss: 0.666004336964255 \t \t Accuracy = 98.32943725585938, \t Validation Loss: 0.3729017969460515, \t Validation accuracy: 98.27890014648438\n",
      "Starting epoch 17\n",
      "Epoch 17 \t\t Training Loss: 0.6610553040120163 \t \t Accuracy = 98.36395263671875, \t Validation Loss: 0.3726289655730041, \t Validation accuracy: 98.2906494140625\n",
      "Starting epoch 18\n",
      "Epoch 18 \t\t Training Loss: 0.6562737294689829 \t \t Accuracy = 98.35881042480469, \t Validation Loss: 0.37265130999492624, \t Validation accuracy: 98.26128387451172\n",
      "Starting epoch 19\n",
      "Epoch 19 \t\t Training Loss: 0.6521088925463364 \t \t Accuracy = 98.3492660522461, \t Validation Loss: 0.37287975420728764, \t Validation accuracy: 98.32002258300781\n",
      "Starting epoch 20\n",
      "Epoch 20 \t\t Training Loss: 0.6473854777396173 \t \t Accuracy = 98.3801040649414, \t Validation Loss: 0.37319665362960414, \t Validation accuracy: 98.32589721679688\n",
      "Starting epoch 21\n",
      "Epoch 21 \t\t Training Loss: 0.6417361854722625 \t \t Accuracy = 98.3977279663086, \t Validation Loss: 0.37324302813463045, \t Validation accuracy: 98.337646484375\n",
      "Starting epoch 22\n",
      "Epoch 22 \t\t Training Loss: 0.6357139048859813 \t \t Accuracy = 98.41682434082031, \t Validation Loss: 0.3726191159925963, \t Validation accuracy: 98.38463592529297\n",
      "Starting epoch 23\n",
      "Epoch 23 \t\t Training Loss: 0.6287662699202398 \t \t Accuracy = 98.4271011352539, \t Validation Loss: 0.37268323804202835, \t Validation accuracy: 98.3963851928711\n",
      "Starting epoch 24\n",
      "Epoch 24 \t\t Training Loss: 0.6182668854279402 \t \t Accuracy = 98.44252014160156, \t Validation Loss: 0.3725302684725377, \t Validation accuracy: 98.3493881225586\n",
      "Starting epoch 25\n",
      "Epoch 25 \t\t Training Loss: 0.6037731602843991 \t \t Accuracy = 98.41902923583984, \t Validation Loss: 0.37257837377793607, \t Validation accuracy: 98.31414794921875\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "#loss_function = nn.functional.binary_cross_entropy\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_fusion2.parameters(), lr=2e-5)\n",
    "batch_size=32\n",
    "n_batches=np.ceil(len(ecg_train)/batch_size).astype(np.int64)\n",
    "valid_batch_size=100\n",
    "valid_batches=np.ceil(len(ecg_valid)/valid_batch_size).astype(np.int64) \n",
    "\n",
    "min_valid_loss = np.inf\n",
    "\n",
    "# Run the training loop\n",
    "for epoch in range(0, 25): # 5 epochs at maximum\n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "    current_tot_loss=0.0\n",
    "    correct=0\n",
    "    i=0\n",
    "    # Iterate over the DataLoader for training data\n",
    "    ind_list = list(range(len(ecg_train)))\n",
    "    shuffle(ind_list)\n",
    "    #train_new  = train[ind_list, :,:,:]\n",
    "    #target_new = target[ind_list,]\n",
    "    while i<n_batches:\n",
    "\n",
    "          # Get inputs\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_wide[i*batch_size:(i+1)*batch_size,]\n",
    "        #local_X, local_y = X_train[i*batch_size:(i+1)*batch_size,], y_train_num[i*batch_size:(i+1)*batch_size,]\n",
    "        local_ecg, local_y, local_ppg, local_ecg_sqi,local_ppg_sqi = ecg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),y_train_num[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ppg_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(), ecg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda(),ppg_sqi_train[ind_list[i*batch_size:(i+1)*batch_size],].cuda()\n",
    "        #if torch.cuda.is_available():\n",
    "        #    local_X, local_y = local_X.cuda(), local_y.cuda()\n",
    "\n",
    "          # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs_c, outputs_ecg, outputs_ppg = model_fusion2(local_ecg.float(),local_ppg.float(),local_ecg_sqi.float(), local_ppg_sqi.float())\n",
    "        \n",
    "        \n",
    "\n",
    "        # Compute loss\n",
    "        loss1 = loss_function(outputs_c, local_y)\n",
    "        loss2 = loss_function(outputs_ecg, local_y)\n",
    "        loss3 = loss_function(outputs_ppg, local_y)\n",
    "        loss=(loss1+loss2+loss3)/3\n",
    "        #loss=loss1\n",
    "        #print(loss)\n",
    "        \n",
    "        #loss = loss_function(outputs, local_y.float())\n",
    "        l2_lambda = 0.01\n",
    "        l2_reg = torch.tensor(0.).cuda()\n",
    "        for param in model_fusion2.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        loss += l2_lambda * l2_reg\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        output = outputs_c.clone()\n",
    "        output= torch.argmax(output, axis=1)\n",
    "        \n",
    "        correct += (output == local_y).float().sum()\n",
    "\n",
    "        # Print statistics\n",
    "        \n",
    "        #current_loss += loss.item()\n",
    "        current_tot_loss+=loss.item()\n",
    "       # if i % 20 == 19:\n",
    "       #     print('Loss after mini-batch %5d: %.3f' %\n",
    "       #         (i + 1, current_loss / 20))\n",
    "       #     current_loss = 0.0\n",
    "        i=i+1\n",
    "        \n",
    "    \n",
    "    \n",
    "    correct_valid=0\n",
    "    current_valid_loss = 0.0\n",
    "    current_valid_tot_loss=0.0\n",
    "    j=0\n",
    "    while j<valid_batches:\n",
    "        model_fusion2.eval()     # Optional when not using Model Specific layer\n",
    "        local_ecg_valid, local_y_valid, local_ppg_valid, local_ecg_sqi_valid,local_ppg_sqi_valid = ecg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),y_valid_num[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ppg_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(), ecg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda(),ppg_sqi_valid[j*valid_batch_size:(j+1)*valid_batch_size,].cuda()\n",
    "        target, target2, target3 = model_fusion2(local_ecg_valid.float(),local_ppg_valid.float(),local_ecg_sqi_valid.float(), local_ppg_sqi_valid.float())\n",
    "        loss1 = loss_function(target,local_y_valid)\n",
    "        loss2 = loss_function(target2,local_y_valid)\n",
    "        loss3 = loss_function(target3,local_y_valid)\n",
    "        #loss=loss1\n",
    "        loss=(loss1+loss2+loss3)/3\n",
    "        current_valid_loss+=loss.item()\n",
    "        #valid_loss = loss.item() \n",
    "        target= torch.argmax(target, axis=1)\n",
    "        correct_valid += (target == local_y_valid).float().sum()\n",
    "        j=j+1\n",
    "    \n",
    "    #print(correct)\n",
    "    #print(current_tot_loss)\n",
    "    accuracy = 100 * correct / len(ecg_train)\n",
    "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {current_tot_loss / n_batches} \\t \\t Accuracy = {accuracy}, \\t Validation Loss: {current_valid_loss/ valid_batches}, \\t Validation accuracy: {100*correct_valid/len(ecg_valid)}')\n",
    "    \n",
    "    if min_valid_loss > (current_valid_loss/valid_batches):\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{current_valid_loss/valid_batches:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = (current_valid_loss/valid_batches)\n",
    "        # Saving State Dict\n",
    "        torch.save(model_fusion2.state_dict(), 'saved_model_fusion_no_noise_0.01_avg_loss.pth')\n",
    "        \n",
    "    \n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a6667d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = fusion_model_v3()\n",
    "model_saved.load_state_dict(torch.load('saved_model_fusion_no_noise_0.01_avg_loss.pth'))\n",
    "model_saved.eval()\n",
    "model_saved=model_saved.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b15c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:149: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:170: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "D:\\conda_envs\\torch_19\\lib\\site-packages\\ipykernel_launcher.py:262: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9933)\n",
      "[[8431   80]\n",
      " [  14 5434]]\n"
     ]
    }
   ],
   "source": [
    "outputs_test,out1,out2 = model_saved(ecg_test.float(), ppg_test.float(), ecg_sqi_test.float(), ppg_sqi_test.float())\n",
    "outputs_test = outputs_test.clone()\n",
    "outputs_test= torch.argmax(outputs_test, axis=1)\n",
    "\n",
    "        \n",
    "correct = (outputs_test == y_test_num).float().sum()\n",
    "print(correct/len(ecg_test))\n",
    "\n",
    "cm=confusion_matrix(y_test_num.cpu(), outputs_test.cpu())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c601f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
